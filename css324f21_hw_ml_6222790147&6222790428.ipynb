{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "css324f21_hw_ml_6222790147&6222790428.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HongKanokkarn/ML_CIFAR10/blob/main/css324f21_hw_ml_6222790147%266222790428.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1co9QUId36Eo"
      },
      "source": [
        "# 6222790147 & 6222790428\n",
        "# Kanonkkarn Pinkeaw & Tandin Dorji\n",
        "# CSS324 Homework Assignment\n",
        "\n",
        "CIFAR10 is a small image classification dataset. Its objective is to classification an 32x32 color image into 10 classes.\n",
        "\n",
        "See https://www.cs.toronto.edu/~kriz/cifar.html and https://keras.io/api/datasets/cifar10/ for more details."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zXtrgRH9oK5"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMSl6MYp33eW",
        "outputId": "129c1df7-71b0-4925-9df0-18c5a3c83000"
      },
      "source": [
        "# Load CIFAR10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "170508288/170498071 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "Vwoz3JDK98Jy",
        "outputId": "c9f42ec5-f5b5-48d0-ad6f-0e89d83a546f"
      },
      "source": [
        "# Plot a training example\n",
        "x = x_train[12, :, :, :]\n",
        "y = y_train[12][0]\n",
        "\n",
        "plt.imshow(x)\n",
        "print(y)        # 7 = horse"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFt4OqeP_Buc"
      },
      "source": [
        "## Question 1\n",
        "\n",
        "Construct a deep neural network containing three hidden layer to classify images in the CIFAR10 dataset. You can choose the numbers of hidden nodes in three layers, appropriate activation functions, regularizers. Use 20% of the training set to validate the model.\n",
        "\n",
        "After the training process, print the training, validation, and test accuracies, as well as plot the training loss and validation loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpuD33bU__mt"
      },
      "source": [
        "#define the training examples\n",
        "\n",
        "# Your implementation for Question 1\n",
        "tf.random.set_seed(11)\n",
        "\n",
        "#Normalize the dataset\n",
        "x_train = x_train/255.0\n",
        "x_test = x_test/255.0\n",
        "\n",
        "y_train = tf.one_hot(y_train,10)\n",
        "y_test = tf.one_hot(y_test,10)\n",
        "\n",
        "x_train = x_train.reshape((-1,32,32,3))\n",
        "x_test = x_test.reshape((-1,32,32,3))\n",
        "\n",
        "y_train = y_train[:,0,:]\n",
        "y_test = y_test[:,0,:]\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFajzbsYHqBy"
      },
      "source": [
        "#Define a model\n",
        "model = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Flatten(input_shape=(32,32,3)),\n",
        "                                    tf.keras.layers.BatchNormalization(),\n",
        "                                    tf.keras.layers.Dropout(0.3),\n",
        "                                    tf.keras.layers.Dense(128, activation = 'relu', kernel_regularizer=tf.keras.regularizers.l2(1e-4)),\n",
        "                                    tf.keras.layers.Dropout(0.3),\n",
        "                                    tf.keras.layers.Dense(64, activation = 'relu', kernel_regularizer=tf.keras.regularizers.l2(1e-4)),\n",
        "                                    tf.keras.layers.BatchNormalization(),\n",
        "                                    tf.keras.layers.Dropout(0.3),\n",
        "                                    tf.keras.layers.Dense(32, activation = 'relu', kernel_regularizer=tf.keras.regularizers.l2(1e-4)),\n",
        "                                    tf.keras.layers.BatchNormalization(),\n",
        "                                    tf.keras.layers.Dropout(0.3),\n",
        "                                    tf.keras.layers.Dense(10, activation = 'softmax'),\n",
        "])\n",
        "model.compile(optimizer='adam',\n",
        "              loss = tf.keras.losses.CategoricalCrossentropy(),\n",
        "              metrics = ['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hgfj9tmE_Q0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7896dd5-f860-44f4-acd6-67bd65c87aab"
      },
      "source": [
        "#Train the model\n",
        "history = model.fit(x_train, y_train, epochs= 200,\n",
        "                    batch_size=1024, shuffle=True,\n",
        "                    validation_split=0.2)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "40/40 [==============================] - 5s 30ms/step - loss: 2.5193 - accuracy: 0.1963 - val_loss: 2.4922 - val_accuracy: 0.1818\n",
            "Epoch 2/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 2.1570 - accuracy: 0.2679 - val_loss: 1.9651 - val_accuracy: 0.3313\n",
            "Epoch 3/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 2.0271 - accuracy: 0.2999 - val_loss: 1.8924 - val_accuracy: 0.3693\n",
            "Epoch 4/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.9412 - accuracy: 0.3279 - val_loss: 1.8236 - val_accuracy: 0.3905\n",
            "Epoch 5/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.8810 - accuracy: 0.3440 - val_loss: 1.7775 - val_accuracy: 0.4094\n",
            "Epoch 6/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.8419 - accuracy: 0.3566 - val_loss: 1.7175 - val_accuracy: 0.4276\n",
            "Epoch 7/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.7984 - accuracy: 0.3732 - val_loss: 1.6705 - val_accuracy: 0.4388\n",
            "Epoch 8/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.7726 - accuracy: 0.3814 - val_loss: 1.6368 - val_accuracy: 0.4498\n",
            "Epoch 9/200\n",
            "40/40 [==============================] - 1s 18ms/step - loss: 1.7463 - accuracy: 0.3895 - val_loss: 1.6087 - val_accuracy: 0.4548\n",
            "Epoch 10/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.7237 - accuracy: 0.3990 - val_loss: 1.5835 - val_accuracy: 0.4577\n",
            "Epoch 11/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.7015 - accuracy: 0.4078 - val_loss: 1.5645 - val_accuracy: 0.4625\n",
            "Epoch 12/200\n",
            "40/40 [==============================] - 1s 18ms/step - loss: 1.6843 - accuracy: 0.4116 - val_loss: 1.5514 - val_accuracy: 0.4656\n",
            "Epoch 13/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.6710 - accuracy: 0.4189 - val_loss: 1.5435 - val_accuracy: 0.4702\n",
            "Epoch 14/200\n",
            "40/40 [==============================] - 1s 18ms/step - loss: 1.6469 - accuracy: 0.4249 - val_loss: 1.5318 - val_accuracy: 0.4772\n",
            "Epoch 15/200\n",
            "40/40 [==============================] - 1s 18ms/step - loss: 1.6434 - accuracy: 0.4269 - val_loss: 1.5221 - val_accuracy: 0.4759\n",
            "Epoch 16/200\n",
            "40/40 [==============================] - 1s 17ms/step - loss: 1.6155 - accuracy: 0.4384 - val_loss: 1.5064 - val_accuracy: 0.4776\n",
            "Epoch 17/200\n",
            "40/40 [==============================] - 1s 18ms/step - loss: 1.6054 - accuracy: 0.4476 - val_loss: 1.4906 - val_accuracy: 0.4831\n",
            "Epoch 18/200\n",
            "40/40 [==============================] - 1s 18ms/step - loss: 1.5984 - accuracy: 0.4443 - val_loss: 1.4890 - val_accuracy: 0.4875\n",
            "Epoch 19/200\n",
            "40/40 [==============================] - 1s 18ms/step - loss: 1.5937 - accuracy: 0.4457 - val_loss: 1.4832 - val_accuracy: 0.4879\n",
            "Epoch 20/200\n",
            "40/40 [==============================] - 1s 18ms/step - loss: 1.5822 - accuracy: 0.4520 - val_loss: 1.4718 - val_accuracy: 0.4932\n",
            "Epoch 21/200\n",
            "40/40 [==============================] - 1s 18ms/step - loss: 1.5748 - accuracy: 0.4557 - val_loss: 1.4654 - val_accuracy: 0.4918\n",
            "Epoch 22/200\n",
            "40/40 [==============================] - 1s 18ms/step - loss: 1.5657 - accuracy: 0.4595 - val_loss: 1.4592 - val_accuracy: 0.4952\n",
            "Epoch 23/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.5511 - accuracy: 0.4646 - val_loss: 1.4620 - val_accuracy: 0.4942\n",
            "Epoch 24/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.5416 - accuracy: 0.4675 - val_loss: 1.4469 - val_accuracy: 0.5006\n",
            "Epoch 25/200\n",
            "40/40 [==============================] - 1s 18ms/step - loss: 1.5293 - accuracy: 0.4732 - val_loss: 1.4482 - val_accuracy: 0.4961\n",
            "Epoch 26/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.5279 - accuracy: 0.4735 - val_loss: 1.4492 - val_accuracy: 0.5018\n",
            "Epoch 27/200\n",
            "40/40 [==============================] - 1s 18ms/step - loss: 1.5231 - accuracy: 0.4761 - val_loss: 1.4410 - val_accuracy: 0.5067\n",
            "Epoch 28/200\n",
            "40/40 [==============================] - 1s 18ms/step - loss: 1.5151 - accuracy: 0.4794 - val_loss: 1.4282 - val_accuracy: 0.5120\n",
            "Epoch 29/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.5066 - accuracy: 0.4841 - val_loss: 1.4366 - val_accuracy: 0.5117\n",
            "Epoch 30/200\n",
            "40/40 [==============================] - 1s 18ms/step - loss: 1.4962 - accuracy: 0.4859 - val_loss: 1.4276 - val_accuracy: 0.5102\n",
            "Epoch 31/200\n",
            "40/40 [==============================] - 1s 18ms/step - loss: 1.4954 - accuracy: 0.4864 - val_loss: 1.4217 - val_accuracy: 0.5171\n",
            "Epoch 32/200\n",
            "40/40 [==============================] - 1s 18ms/step - loss: 1.4984 - accuracy: 0.4873 - val_loss: 1.4292 - val_accuracy: 0.5098\n",
            "Epoch 33/200\n",
            "40/40 [==============================] - 1s 17ms/step - loss: 1.4904 - accuracy: 0.4889 - val_loss: 1.4271 - val_accuracy: 0.5126\n",
            "Epoch 34/200\n",
            "40/40 [==============================] - 1s 18ms/step - loss: 1.4837 - accuracy: 0.4924 - val_loss: 1.4224 - val_accuracy: 0.5151\n",
            "Epoch 35/200\n",
            "40/40 [==============================] - 1s 18ms/step - loss: 1.4792 - accuracy: 0.4948 - val_loss: 1.4159 - val_accuracy: 0.5166\n",
            "Epoch 36/200\n",
            "40/40 [==============================] - 1s 18ms/step - loss: 1.4793 - accuracy: 0.4938 - val_loss: 1.4250 - val_accuracy: 0.5165\n",
            "Epoch 37/200\n",
            "40/40 [==============================] - 1s 18ms/step - loss: 1.4725 - accuracy: 0.4996 - val_loss: 1.4123 - val_accuracy: 0.5171\n",
            "Epoch 38/200\n",
            "40/40 [==============================] - 1s 18ms/step - loss: 1.4767 - accuracy: 0.4941 - val_loss: 1.4188 - val_accuracy: 0.5163\n",
            "Epoch 39/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.4616 - accuracy: 0.5052 - val_loss: 1.4148 - val_accuracy: 0.5182\n",
            "Epoch 40/200\n",
            "40/40 [==============================] - 1s 18ms/step - loss: 1.4625 - accuracy: 0.5032 - val_loss: 1.4150 - val_accuracy: 0.5219\n",
            "Epoch 41/200\n",
            "40/40 [==============================] - 1s 18ms/step - loss: 1.4637 - accuracy: 0.5025 - val_loss: 1.4166 - val_accuracy: 0.5173\n",
            "Epoch 42/200\n",
            "40/40 [==============================] - 1s 18ms/step - loss: 1.4478 - accuracy: 0.5087 - val_loss: 1.4142 - val_accuracy: 0.5166\n",
            "Epoch 43/200\n",
            "40/40 [==============================] - 1s 18ms/step - loss: 1.4464 - accuracy: 0.5088 - val_loss: 1.4074 - val_accuracy: 0.5232\n",
            "Epoch 44/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.4518 - accuracy: 0.5076 - val_loss: 1.4083 - val_accuracy: 0.5246\n",
            "Epoch 45/200\n",
            "40/40 [==============================] - 1s 18ms/step - loss: 1.4384 - accuracy: 0.5110 - val_loss: 1.4020 - val_accuracy: 0.5240\n",
            "Epoch 46/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.4477 - accuracy: 0.5140 - val_loss: 1.4086 - val_accuracy: 0.5248\n",
            "Epoch 47/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.4345 - accuracy: 0.5145 - val_loss: 1.4020 - val_accuracy: 0.5268\n",
            "Epoch 48/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.4319 - accuracy: 0.5167 - val_loss: 1.4015 - val_accuracy: 0.5262\n",
            "Epoch 49/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.4269 - accuracy: 0.5200 - val_loss: 1.3960 - val_accuracy: 0.5275\n",
            "Epoch 50/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.4360 - accuracy: 0.5118 - val_loss: 1.4041 - val_accuracy: 0.5253\n",
            "Epoch 51/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.4322 - accuracy: 0.5152 - val_loss: 1.3935 - val_accuracy: 0.5300\n",
            "Epoch 52/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.4273 - accuracy: 0.5174 - val_loss: 1.3956 - val_accuracy: 0.5301\n",
            "Epoch 53/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.4246 - accuracy: 0.5191 - val_loss: 1.4010 - val_accuracy: 0.5223\n",
            "Epoch 54/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.4158 - accuracy: 0.5227 - val_loss: 1.4017 - val_accuracy: 0.5261\n",
            "Epoch 55/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.4169 - accuracy: 0.5242 - val_loss: 1.3950 - val_accuracy: 0.5238\n",
            "Epoch 56/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.4222 - accuracy: 0.5226 - val_loss: 1.3978 - val_accuracy: 0.5262\n",
            "Epoch 57/200\n",
            "40/40 [==============================] - 1s 18ms/step - loss: 1.4166 - accuracy: 0.5278 - val_loss: 1.3978 - val_accuracy: 0.5261\n",
            "Epoch 58/200\n",
            "40/40 [==============================] - 1s 18ms/step - loss: 1.4107 - accuracy: 0.5271 - val_loss: 1.4082 - val_accuracy: 0.5266\n",
            "Epoch 59/200\n",
            "40/40 [==============================] - 1s 18ms/step - loss: 1.4149 - accuracy: 0.5258 - val_loss: 1.3957 - val_accuracy: 0.5316\n",
            "Epoch 60/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.4154 - accuracy: 0.5272 - val_loss: 1.3962 - val_accuracy: 0.5336\n",
            "Epoch 61/200\n",
            "40/40 [==============================] - 1s 18ms/step - loss: 1.4029 - accuracy: 0.5302 - val_loss: 1.3961 - val_accuracy: 0.5307\n",
            "Epoch 62/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.3921 - accuracy: 0.5349 - val_loss: 1.3995 - val_accuracy: 0.5268\n",
            "Epoch 63/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.4117 - accuracy: 0.5279 - val_loss: 1.3925 - val_accuracy: 0.5330\n",
            "Epoch 64/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.4008 - accuracy: 0.5304 - val_loss: 1.3990 - val_accuracy: 0.5316\n",
            "Epoch 65/200\n",
            "40/40 [==============================] - 1s 18ms/step - loss: 1.3883 - accuracy: 0.5372 - val_loss: 1.3964 - val_accuracy: 0.5315\n",
            "Epoch 66/200\n",
            "40/40 [==============================] - 1s 18ms/step - loss: 1.3959 - accuracy: 0.5336 - val_loss: 1.3958 - val_accuracy: 0.5327\n",
            "Epoch 67/200\n",
            "40/40 [==============================] - 1s 18ms/step - loss: 1.3901 - accuracy: 0.5378 - val_loss: 1.3977 - val_accuracy: 0.5305\n",
            "Epoch 68/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.3859 - accuracy: 0.5419 - val_loss: 1.3967 - val_accuracy: 0.5294\n",
            "Epoch 69/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.3897 - accuracy: 0.5381 - val_loss: 1.4027 - val_accuracy: 0.5254\n",
            "Epoch 70/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.3901 - accuracy: 0.5376 - val_loss: 1.3968 - val_accuracy: 0.5327\n",
            "Epoch 71/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.3953 - accuracy: 0.5367 - val_loss: 1.3946 - val_accuracy: 0.5370\n",
            "Epoch 72/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.3761 - accuracy: 0.5430 - val_loss: 1.3930 - val_accuracy: 0.5376\n",
            "Epoch 73/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3850 - accuracy: 0.5361 - val_loss: 1.3951 - val_accuracy: 0.5354\n",
            "Epoch 74/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3743 - accuracy: 0.5437 - val_loss: 1.4012 - val_accuracy: 0.5318\n",
            "Epoch 75/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.3752 - accuracy: 0.5407 - val_loss: 1.3921 - val_accuracy: 0.5339\n",
            "Epoch 76/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3730 - accuracy: 0.5440 - val_loss: 1.3984 - val_accuracy: 0.5373\n",
            "Epoch 77/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.3739 - accuracy: 0.5447 - val_loss: 1.3955 - val_accuracy: 0.5384\n",
            "Epoch 78/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3830 - accuracy: 0.5435 - val_loss: 1.3992 - val_accuracy: 0.5343\n",
            "Epoch 79/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3734 - accuracy: 0.5473 - val_loss: 1.3910 - val_accuracy: 0.5363\n",
            "Epoch 80/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3670 - accuracy: 0.5478 - val_loss: 1.3991 - val_accuracy: 0.5336\n",
            "Epoch 81/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.3673 - accuracy: 0.5463 - val_loss: 1.3903 - val_accuracy: 0.5391\n",
            "Epoch 82/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.3607 - accuracy: 0.5488 - val_loss: 1.3918 - val_accuracy: 0.5398\n",
            "Epoch 83/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3595 - accuracy: 0.5494 - val_loss: 1.3981 - val_accuracy: 0.5374\n",
            "Epoch 84/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3560 - accuracy: 0.5504 - val_loss: 1.3967 - val_accuracy: 0.5351\n",
            "Epoch 85/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3639 - accuracy: 0.5494 - val_loss: 1.3954 - val_accuracy: 0.5379\n",
            "Epoch 86/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3564 - accuracy: 0.5523 - val_loss: 1.3987 - val_accuracy: 0.5352\n",
            "Epoch 87/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3546 - accuracy: 0.5507 - val_loss: 1.3971 - val_accuracy: 0.5337\n",
            "Epoch 88/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3529 - accuracy: 0.5558 - val_loss: 1.3986 - val_accuracy: 0.5344\n",
            "Epoch 89/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3550 - accuracy: 0.5565 - val_loss: 1.3917 - val_accuracy: 0.5376\n",
            "Epoch 90/200\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 1.3508 - accuracy: 0.5535 - val_loss: 1.3935 - val_accuracy: 0.5370\n",
            "Epoch 91/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3622 - accuracy: 0.5518 - val_loss: 1.4035 - val_accuracy: 0.5337\n",
            "Epoch 92/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3517 - accuracy: 0.5554 - val_loss: 1.3935 - val_accuracy: 0.5414\n",
            "Epoch 93/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3504 - accuracy: 0.5527 - val_loss: 1.3944 - val_accuracy: 0.5356\n",
            "Epoch 94/200\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 1.3521 - accuracy: 0.5555 - val_loss: 1.3921 - val_accuracy: 0.5349\n",
            "Epoch 95/200\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 1.3459 - accuracy: 0.5567 - val_loss: 1.3942 - val_accuracy: 0.5405\n",
            "Epoch 96/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.3645 - accuracy: 0.5510 - val_loss: 1.3986 - val_accuracy: 0.5358\n",
            "Epoch 97/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.3497 - accuracy: 0.5550 - val_loss: 1.3944 - val_accuracy: 0.5400\n",
            "Epoch 98/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.3538 - accuracy: 0.5544 - val_loss: 1.3966 - val_accuracy: 0.5384\n",
            "Epoch 99/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3503 - accuracy: 0.5557 - val_loss: 1.4052 - val_accuracy: 0.5389\n",
            "Epoch 100/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3626 - accuracy: 0.5511 - val_loss: 1.4013 - val_accuracy: 0.5366\n",
            "Epoch 101/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.3483 - accuracy: 0.5597 - val_loss: 1.3950 - val_accuracy: 0.5386\n",
            "Epoch 102/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3444 - accuracy: 0.5607 - val_loss: 1.3962 - val_accuracy: 0.5397\n",
            "Epoch 103/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3418 - accuracy: 0.5598 - val_loss: 1.3995 - val_accuracy: 0.5377\n",
            "Epoch 104/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3512 - accuracy: 0.5566 - val_loss: 1.3987 - val_accuracy: 0.5354\n",
            "Epoch 105/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3504 - accuracy: 0.5589 - val_loss: 1.3995 - val_accuracy: 0.5380\n",
            "Epoch 106/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.3470 - accuracy: 0.5610 - val_loss: 1.3964 - val_accuracy: 0.5397\n",
            "Epoch 107/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3498 - accuracy: 0.5597 - val_loss: 1.3923 - val_accuracy: 0.5400\n",
            "Epoch 108/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3284 - accuracy: 0.5653 - val_loss: 1.3992 - val_accuracy: 0.5364\n",
            "Epoch 109/200\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 1.3340 - accuracy: 0.5638 - val_loss: 1.4032 - val_accuracy: 0.5359\n",
            "Epoch 110/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.3409 - accuracy: 0.5620 - val_loss: 1.4000 - val_accuracy: 0.5384\n",
            "Epoch 111/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.3506 - accuracy: 0.5586 - val_loss: 1.4062 - val_accuracy: 0.5386\n",
            "Epoch 112/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.3415 - accuracy: 0.5652 - val_loss: 1.3931 - val_accuracy: 0.5385\n",
            "Epoch 113/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3400 - accuracy: 0.5619 - val_loss: 1.4042 - val_accuracy: 0.5433\n",
            "Epoch 114/200\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 1.3412 - accuracy: 0.5621 - val_loss: 1.4030 - val_accuracy: 0.5363\n",
            "Epoch 115/200\n",
            "40/40 [==============================] - 1s 22ms/step - loss: 1.3312 - accuracy: 0.5645 - val_loss: 1.4037 - val_accuracy: 0.5369\n",
            "Epoch 116/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3336 - accuracy: 0.5639 - val_loss: 1.3938 - val_accuracy: 0.5406\n",
            "Epoch 117/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.3322 - accuracy: 0.5668 - val_loss: 1.4028 - val_accuracy: 0.5393\n",
            "Epoch 118/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.3316 - accuracy: 0.5651 - val_loss: 1.3951 - val_accuracy: 0.5407\n",
            "Epoch 119/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3338 - accuracy: 0.5643 - val_loss: 1.4023 - val_accuracy: 0.5375\n",
            "Epoch 120/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3463 - accuracy: 0.5591 - val_loss: 1.4094 - val_accuracy: 0.5341\n",
            "Epoch 121/200\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 1.3387 - accuracy: 0.5619 - val_loss: 1.4001 - val_accuracy: 0.5403\n",
            "Epoch 122/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.3509 - accuracy: 0.5602 - val_loss: 1.4038 - val_accuracy: 0.5396\n",
            "Epoch 123/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3442 - accuracy: 0.5631 - val_loss: 1.4068 - val_accuracy: 0.5357\n",
            "Epoch 124/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.3422 - accuracy: 0.5626 - val_loss: 1.4032 - val_accuracy: 0.5381\n",
            "Epoch 125/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3405 - accuracy: 0.5627 - val_loss: 1.4046 - val_accuracy: 0.5323\n",
            "Epoch 126/200\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 1.3416 - accuracy: 0.5622 - val_loss: 1.4059 - val_accuracy: 0.5370\n",
            "Epoch 127/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3361 - accuracy: 0.5661 - val_loss: 1.3950 - val_accuracy: 0.5357\n",
            "Epoch 128/200\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 1.3234 - accuracy: 0.5692 - val_loss: 1.4071 - val_accuracy: 0.5368\n",
            "Epoch 129/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3270 - accuracy: 0.5699 - val_loss: 1.4033 - val_accuracy: 0.5408\n",
            "Epoch 130/200\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 1.3297 - accuracy: 0.5659 - val_loss: 1.4041 - val_accuracy: 0.5431\n",
            "Epoch 131/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3307 - accuracy: 0.5678 - val_loss: 1.3994 - val_accuracy: 0.5426\n",
            "Epoch 132/200\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 1.3200 - accuracy: 0.5706 - val_loss: 1.3936 - val_accuracy: 0.5408\n",
            "Epoch 133/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.3277 - accuracy: 0.5692 - val_loss: 1.3953 - val_accuracy: 0.5432\n",
            "Epoch 134/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.3299 - accuracy: 0.5671 - val_loss: 1.3919 - val_accuracy: 0.5449\n",
            "Epoch 135/200\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 1.3290 - accuracy: 0.5656 - val_loss: 1.3990 - val_accuracy: 0.5404\n",
            "Epoch 136/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3294 - accuracy: 0.5681 - val_loss: 1.4009 - val_accuracy: 0.5424\n",
            "Epoch 137/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3164 - accuracy: 0.5709 - val_loss: 1.3952 - val_accuracy: 0.5445\n",
            "Epoch 138/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.3343 - accuracy: 0.5677 - val_loss: 1.4029 - val_accuracy: 0.5407\n",
            "Epoch 139/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.3273 - accuracy: 0.5704 - val_loss: 1.4012 - val_accuracy: 0.5404\n",
            "Epoch 140/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.3213 - accuracy: 0.5710 - val_loss: 1.4006 - val_accuracy: 0.5393\n",
            "Epoch 141/200\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 1.3186 - accuracy: 0.5727 - val_loss: 1.4001 - val_accuracy: 0.5457\n",
            "Epoch 142/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3205 - accuracy: 0.5688 - val_loss: 1.4034 - val_accuracy: 0.5440\n",
            "Epoch 143/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.3353 - accuracy: 0.5665 - val_loss: 1.3977 - val_accuracy: 0.5407\n",
            "Epoch 144/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.3242 - accuracy: 0.5728 - val_loss: 1.3929 - val_accuracy: 0.5466\n",
            "Epoch 145/200\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 1.3217 - accuracy: 0.5705 - val_loss: 1.3990 - val_accuracy: 0.5447\n",
            "Epoch 146/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.3242 - accuracy: 0.5713 - val_loss: 1.4061 - val_accuracy: 0.5400\n",
            "Epoch 147/200\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 1.3313 - accuracy: 0.5681 - val_loss: 1.4079 - val_accuracy: 0.5389\n",
            "Epoch 148/200\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 1.3189 - accuracy: 0.5741 - val_loss: 1.4046 - val_accuracy: 0.5417\n",
            "Epoch 149/200\n",
            "40/40 [==============================] - 1s 18ms/step - loss: 1.3321 - accuracy: 0.5653 - val_loss: 1.3952 - val_accuracy: 0.5431\n",
            "Epoch 150/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.3131 - accuracy: 0.5761 - val_loss: 1.4021 - val_accuracy: 0.5416\n",
            "Epoch 151/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.3258 - accuracy: 0.5710 - val_loss: 1.4090 - val_accuracy: 0.5358\n",
            "Epoch 152/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.3246 - accuracy: 0.5735 - val_loss: 1.3990 - val_accuracy: 0.5425\n",
            "Epoch 153/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.3198 - accuracy: 0.5736 - val_loss: 1.3985 - val_accuracy: 0.5422\n",
            "Epoch 154/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.3150 - accuracy: 0.5719 - val_loss: 1.3983 - val_accuracy: 0.5441\n",
            "Epoch 155/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.3087 - accuracy: 0.5770 - val_loss: 1.4049 - val_accuracy: 0.5387\n",
            "Epoch 156/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.3176 - accuracy: 0.5737 - val_loss: 1.4048 - val_accuracy: 0.5427\n",
            "Epoch 157/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.3263 - accuracy: 0.5727 - val_loss: 1.4069 - val_accuracy: 0.5432\n",
            "Epoch 158/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.3284 - accuracy: 0.5698 - val_loss: 1.4116 - val_accuracy: 0.5394\n",
            "Epoch 159/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.3251 - accuracy: 0.5716 - val_loss: 1.4071 - val_accuracy: 0.5398\n",
            "Epoch 160/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3107 - accuracy: 0.5771 - val_loss: 1.4025 - val_accuracy: 0.5442\n",
            "Epoch 161/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3187 - accuracy: 0.5736 - val_loss: 1.4033 - val_accuracy: 0.5429\n",
            "Epoch 162/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.3097 - accuracy: 0.5767 - val_loss: 1.4067 - val_accuracy: 0.5435\n",
            "Epoch 163/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3333 - accuracy: 0.5706 - val_loss: 1.3995 - val_accuracy: 0.5468\n",
            "Epoch 164/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3172 - accuracy: 0.5754 - val_loss: 1.4074 - val_accuracy: 0.5414\n",
            "Epoch 165/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3302 - accuracy: 0.5712 - val_loss: 1.4065 - val_accuracy: 0.5416\n",
            "Epoch 166/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3145 - accuracy: 0.5786 - val_loss: 1.4097 - val_accuracy: 0.5371\n",
            "Epoch 167/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3076 - accuracy: 0.5781 - val_loss: 1.4095 - val_accuracy: 0.5384\n",
            "Epoch 168/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3201 - accuracy: 0.5709 - val_loss: 1.4122 - val_accuracy: 0.5387\n",
            "Epoch 169/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3272 - accuracy: 0.5695 - val_loss: 1.4063 - val_accuracy: 0.5407\n",
            "Epoch 170/200\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 1.3078 - accuracy: 0.5767 - val_loss: 1.4043 - val_accuracy: 0.5396\n",
            "Epoch 171/200\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 1.3095 - accuracy: 0.5775 - val_loss: 1.3964 - val_accuracy: 0.5424\n",
            "Epoch 172/200\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 1.3119 - accuracy: 0.5764 - val_loss: 1.4016 - val_accuracy: 0.5410\n",
            "Epoch 173/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3098 - accuracy: 0.5800 - val_loss: 1.4145 - val_accuracy: 0.5407\n",
            "Epoch 174/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.3288 - accuracy: 0.5723 - val_loss: 1.4024 - val_accuracy: 0.5444\n",
            "Epoch 175/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3171 - accuracy: 0.5735 - val_loss: 1.4074 - val_accuracy: 0.5438\n",
            "Epoch 176/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3177 - accuracy: 0.5755 - val_loss: 1.4071 - val_accuracy: 0.5415\n",
            "Epoch 177/200\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 1.3082 - accuracy: 0.5811 - val_loss: 1.4010 - val_accuracy: 0.5438\n",
            "Epoch 178/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3067 - accuracy: 0.5797 - val_loss: 1.4035 - val_accuracy: 0.5439\n",
            "Epoch 179/200\n",
            "40/40 [==============================] - 1s 22ms/step - loss: 1.3143 - accuracy: 0.5742 - val_loss: 1.4104 - val_accuracy: 0.5361\n",
            "Epoch 180/200\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 1.3213 - accuracy: 0.5767 - val_loss: 1.4110 - val_accuracy: 0.5412\n",
            "Epoch 181/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3137 - accuracy: 0.5787 - val_loss: 1.4048 - val_accuracy: 0.5410\n",
            "Epoch 182/200\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 1.3157 - accuracy: 0.5752 - val_loss: 1.4106 - val_accuracy: 0.5392\n",
            "Epoch 183/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.3123 - accuracy: 0.5758 - val_loss: 1.4067 - val_accuracy: 0.5443\n",
            "Epoch 184/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.3152 - accuracy: 0.5739 - val_loss: 1.4064 - val_accuracy: 0.5379\n",
            "Epoch 185/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.3141 - accuracy: 0.5793 - val_loss: 1.4054 - val_accuracy: 0.5388\n",
            "Epoch 186/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3124 - accuracy: 0.5763 - val_loss: 1.4077 - val_accuracy: 0.5354\n",
            "Epoch 187/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3090 - accuracy: 0.5779 - val_loss: 1.4049 - val_accuracy: 0.5405\n",
            "Epoch 188/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3097 - accuracy: 0.5790 - val_loss: 1.4061 - val_accuracy: 0.5425\n",
            "Epoch 189/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3090 - accuracy: 0.5776 - val_loss: 1.4059 - val_accuracy: 0.5406\n",
            "Epoch 190/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3178 - accuracy: 0.5768 - val_loss: 1.4042 - val_accuracy: 0.5422\n",
            "Epoch 191/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.3011 - accuracy: 0.5810 - val_loss: 1.4046 - val_accuracy: 0.5397\n",
            "Epoch 192/200\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 1.3148 - accuracy: 0.5764 - val_loss: 1.4150 - val_accuracy: 0.5392\n",
            "Epoch 193/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.3037 - accuracy: 0.5827 - val_loss: 1.4061 - val_accuracy: 0.5452\n",
            "Epoch 194/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3076 - accuracy: 0.5789 - val_loss: 1.4039 - val_accuracy: 0.5400\n",
            "Epoch 195/200\n",
            "40/40 [==============================] - 1s 22ms/step - loss: 1.3179 - accuracy: 0.5743 - val_loss: 1.4110 - val_accuracy: 0.5414\n",
            "Epoch 196/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3171 - accuracy: 0.5792 - val_loss: 1.4097 - val_accuracy: 0.5417\n",
            "Epoch 197/200\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 1.3055 - accuracy: 0.5767 - val_loss: 1.4185 - val_accuracy: 0.5366\n",
            "Epoch 198/200\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 1.3071 - accuracy: 0.5776 - val_loss: 1.4127 - val_accuracy: 0.5395\n",
            "Epoch 199/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.3122 - accuracy: 0.5800 - val_loss: 1.4060 - val_accuracy: 0.5413\n",
            "Epoch 200/200\n",
            "40/40 [==============================] - 1s 19ms/step - loss: 1.3076 - accuracy: 0.5774 - val_loss: 1.4045 - val_accuracy: 0.5426\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTS6kxLTFQXH",
        "outputId": "e18b2cf1-ad33-408d-fc08-20a4c2d9f6f0"
      },
      "source": [
        "#Evaluate the model\n",
        "\n",
        "print(\"Training Accuracy\")\n",
        "print(model.evaluate(x_train, y_train, verbose = 0))\n",
        "print(\" \")\n",
        "print(\"Test Accuracy\")\n",
        "print(model.evaluate(x_test, y_test, verbose = 0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy\n",
            "[1.0568543672561646, 0.6757799983024597]\n",
            " \n",
            "Test Accuracy\n",
            "[1.3951107263565063, 0.5389000177383423]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "3Amk91Chjzqz",
        "outputId": "56727778-f8ff-4aca-e03d-658573242c74"
      },
      "source": [
        "# Plot the training loss and validation loss\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training loss', 'validation loss'], loc='upper right')\n",
        "plt.show()\n",
        "\n",
        "#Display all loss and val_loss values\n",
        "print(history.history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': [2.519322633743286, 2.156991720199585, 2.0270960330963135, 1.9411834478378296, 1.8809804916381836, 1.8419214487075806, 1.7983639240264893, 1.7725508213043213, 1.7462592124938965, 1.7237138748168945, 1.70149564743042, 1.6842585802078247, 1.670975923538208, 1.6468654870986938, 1.6433686017990112, 1.615455150604248, 1.6054155826568604, 1.5984315872192383, 1.5936591625213623, 1.582226037979126, 1.5748300552368164, 1.5657240152359009, 1.5511400699615479, 1.541619896888733, 1.5292813777923584, 1.5279346704483032, 1.5231307744979858, 1.5150519609451294, 1.506561279296875, 1.4961538314819336, 1.4953796863555908, 1.4984376430511475, 1.490368366241455, 1.4836795330047607, 1.479182243347168, 1.4792828559875488, 1.472546935081482, 1.47672700881958, 1.4615787267684937, 1.4625095129013062, 1.4636621475219727, 1.4478023052215576, 1.4464226961135864, 1.4517852067947388, 1.4384338855743408, 1.4477484226226807, 1.4344733953475952, 1.431949257850647, 1.4268882274627686, 1.4360120296478271, 1.4321705102920532, 1.4273035526275635, 1.424557089805603, 1.4158393144607544, 1.416892170906067, 1.4222098588943481, 1.4166229963302612, 1.41071355342865, 1.414851427078247, 1.4154082536697388, 1.402887225151062, 1.3921236991882324, 1.4116724729537964, 1.4007830619812012, 1.3882956504821777, 1.3959167003631592, 1.3901348114013672, 1.385880708694458, 1.3896600008010864, 1.3901395797729492, 1.395320177078247, 1.3761414289474487, 1.3849517107009888, 1.3742903470993042, 1.3751803636550903, 1.3730283975601196, 1.3738508224487305, 1.3829824924468994, 1.3733725547790527, 1.3669849634170532, 1.367272138595581, 1.360662579536438, 1.3595471382141113, 1.3559529781341553, 1.3638842105865479, 1.356401801109314, 1.3545907735824585, 1.352918028831482, 1.3549754619598389, 1.3507927656173706, 1.3622032403945923, 1.3516653776168823, 1.3504406213760376, 1.3520565032958984, 1.3458540439605713, 1.3645315170288086, 1.3497271537780762, 1.3538432121276855, 1.3503234386444092, 1.3625515699386597, 1.3483340740203857, 1.3444393873214722, 1.34181809425354, 1.351187825202942, 1.3503673076629639, 1.3469616174697876, 1.3497895002365112, 1.3284056186676025, 1.3340376615524292, 1.3409045934677124, 1.3506495952606201, 1.3415454626083374, 1.3400413990020752, 1.3412086963653564, 1.3311851024627686, 1.3335570096969604, 1.332152247428894, 1.3315956592559814, 1.3338477611541748, 1.346300482749939, 1.3386560678482056, 1.3508586883544922, 1.3441911935806274, 1.3421636819839478, 1.340452790260315, 1.3416023254394531, 1.3360981941223145, 1.3233741521835327, 1.3269942998886108, 1.32970130443573, 1.330735206604004, 1.320048451423645, 1.3277435302734375, 1.3298839330673218, 1.3290432691574097, 1.3294154405593872, 1.316384196281433, 1.3342779874801636, 1.3273357152938843, 1.3213411569595337, 1.3186322450637817, 1.3204683065414429, 1.335264801979065, 1.324173927307129, 1.321700930595398, 1.3242181539535522, 1.3312528133392334, 1.3189077377319336, 1.332133173942566, 1.3131372928619385, 1.3258150815963745, 1.3245892524719238, 1.3198269605636597, 1.3149627447128296, 1.308748483657837, 1.3176249265670776, 1.3262660503387451, 1.3283597230911255, 1.3251491785049438, 1.3106902837753296, 1.318743109703064, 1.3097070455551147, 1.3333401679992676, 1.3171865940093994, 1.3302266597747803, 1.3144609928131104, 1.3075944185256958, 1.3201282024383545, 1.3271799087524414, 1.3077610731124878, 1.309493899345398, 1.3119096755981445, 1.3098058700561523, 1.3287805318832397, 1.3171367645263672, 1.3177427053451538, 1.308197021484375, 1.3067048788070679, 1.314283847808838, 1.3213404417037964, 1.3137319087982178, 1.3157211542129517, 1.3123482465744019, 1.3152416944503784, 1.314147710800171, 1.3124159574508667, 1.3090404272079468, 1.3096858263015747, 1.309022068977356, 1.317777395248413, 1.3010737895965576, 1.3148345947265625, 1.3037134408950806, 1.3075556755065918, 1.317905068397522, 1.3171173334121704, 1.3055400848388672, 1.3070827722549438, 1.3121651411056519, 1.3076305389404297], 'accuracy': [0.19625000655651093, 0.2678999900817871, 0.2999249994754791, 0.3278999924659729, 0.3439750075340271, 0.35657501220703125, 0.3731749951839447, 0.38144999742507935, 0.38952499628067017, 0.39902499318122864, 0.4077500104904175, 0.4116249978542328, 0.4188750088214874, 0.4249249994754791, 0.4268999993801117, 0.43837499618530273, 0.44757500290870667, 0.44429999589920044, 0.44565001130104065, 0.4519749879837036, 0.45567500591278076, 0.4595249891281128, 0.46459999680519104, 0.4674749970436096, 0.4731749892234802, 0.4735249876976013, 0.47612500190734863, 0.47940000891685486, 0.4841249883174896, 0.48590001463890076, 0.4864250123500824, 0.4873499870300293, 0.48887500166893005, 0.492374986410141, 0.4947749972343445, 0.49377501010894775, 0.4995500147342682, 0.49412500858306885, 0.5052250027656555, 0.5031999945640564, 0.5025249719619751, 0.5086749792098999, 0.5088250041007996, 0.5075749754905701, 0.5109999775886536, 0.5139750242233276, 0.5145000219345093, 0.5167499780654907, 0.5200499892234802, 0.5118250250816345, 0.5151749849319458, 0.5174000263214111, 0.5190500020980835, 0.5226500034332275, 0.5242499709129333, 0.522599995136261, 0.5278000235557556, 0.5271000266075134, 0.5257999897003174, 0.5271999835968018, 0.5302249789237976, 0.5348749756813049, 0.5279499888420105, 0.5304499864578247, 0.5372499823570251, 0.5335999727249146, 0.5377500057220459, 0.5418999791145325, 0.538100004196167, 0.5376250147819519, 0.5367000102996826, 0.5430499911308289, 0.5361499786376953, 0.5436999797821045, 0.5406500101089478, 0.5440000295639038, 0.5446749925613403, 0.543524980545044, 0.5472999811172485, 0.5477749705314636, 0.5462999939918518, 0.5487750172615051, 0.5493500232696533, 0.5504000186920166, 0.5493749976158142, 0.5522500276565552, 0.550724983215332, 0.5558249950408936, 0.5564500093460083, 0.553475022315979, 0.5517500042915344, 0.555400013923645, 0.5526999831199646, 0.555525004863739, 0.5566750168800354, 0.5509750247001648, 0.5549749732017517, 0.5543500185012817, 0.5557249784469604, 0.5510749816894531, 0.5597000122070312, 0.560699999332428, 0.5598499774932861, 0.5566499829292297, 0.558899998664856, 0.5610250234603882, 0.5597249865531921, 0.5652750134468079, 0.5637999773025513, 0.5620250105857849, 0.5586000084877014, 0.5651999711990356, 0.5618749856948853, 0.5620999932289124, 0.56454998254776, 0.56392502784729, 0.5667999982833862, 0.5651249885559082, 0.5642750263214111, 0.5590999722480774, 0.5618500113487244, 0.5601500272750854, 0.5631250143051147, 0.5625749826431274, 0.5626749992370605, 0.5622249841690063, 0.566100001335144, 0.5691999793052673, 0.5698750019073486, 0.5659250020980835, 0.5678250193595886, 0.5705749988555908, 0.569225013256073, 0.5671250224113464, 0.5655750036239624, 0.5680500268936157, 0.5709499716758728, 0.5677000284194946, 0.5703750252723694, 0.5709750056266785, 0.5726500153541565, 0.5687999725341797, 0.5665249824523926, 0.5728499889373779, 0.5704500079154968, 0.5712500214576721, 0.5680750012397766, 0.5741000175476074, 0.5653250217437744, 0.57607501745224, 0.5709750056266785, 0.5735250115394592, 0.5736250281333923, 0.5718500018119812, 0.5770249962806702, 0.5736749768257141, 0.5726749897003174, 0.5697500109672546, 0.5716249942779541, 0.5770750045776367, 0.5736250281333923, 0.5766749978065491, 0.5705749988555908, 0.5753999948501587, 0.5711749792098999, 0.5785750150680542, 0.5781000256538391, 0.5708749890327454, 0.569474995136261, 0.5767499804496765, 0.5775250196456909, 0.5764250159263611, 0.580049991607666, 0.5723000168800354, 0.5735499858856201, 0.5755000114440918, 0.5810750126838684, 0.579675018787384, 0.5742499828338623, 0.57669997215271, 0.5787249803543091, 0.5751500129699707, 0.5758249759674072, 0.5739250183105469, 0.5793250203132629, 0.5763499736785889, 0.577875018119812, 0.5789999961853027, 0.5775750279426575, 0.5767999887466431, 0.5809749960899353, 0.576449990272522, 0.5826749801635742, 0.5789499878883362, 0.5742999911308289, 0.5791500210762024, 0.5767499804496765, 0.5776000022888184, 0.580049991607666, 0.5774000287055969], 'val_loss': [2.4922397136688232, 1.9651074409484863, 1.8923941850662231, 1.8236380815505981, 1.7775496244430542, 1.7175058126449585, 1.6705433130264282, 1.636770486831665, 1.6087357997894287, 1.5834908485412598, 1.5645380020141602, 1.5514154434204102, 1.5435243844985962, 1.5317730903625488, 1.5221387147903442, 1.506401538848877, 1.4906034469604492, 1.48899245262146, 1.4831907749176025, 1.4717949628829956, 1.4654133319854736, 1.459198236465454, 1.461991786956787, 1.4469189643859863, 1.4482170343399048, 1.449249029159546, 1.4409501552581787, 1.4281624555587769, 1.4366164207458496, 1.4275765419006348, 1.421725869178772, 1.4292064905166626, 1.4271196126937866, 1.4224368333816528, 1.415947437286377, 1.425026535987854, 1.4123018980026245, 1.4188218116760254, 1.4147732257843018, 1.4149620532989502, 1.4165892601013184, 1.4141743183135986, 1.4074409008026123, 1.4082525968551636, 1.402021884918213, 1.4085513353347778, 1.4019523859024048, 1.4014568328857422, 1.3959945440292358, 1.4040608406066895, 1.3935068845748901, 1.3956068754196167, 1.4010096788406372, 1.4017378091812134, 1.3950417041778564, 1.3978478908538818, 1.3977519273757935, 1.4081621170043945, 1.395708441734314, 1.3961687088012695, 1.3960824012756348, 1.3995472192764282, 1.3924936056137085, 1.3990252017974854, 1.396360158920288, 1.3957808017730713, 1.3977433443069458, 1.3967344760894775, 1.4027087688446045, 1.3967876434326172, 1.3945879936218262, 1.3930284976959229, 1.395058274269104, 1.4012082815170288, 1.3921386003494263, 1.3984320163726807, 1.3955483436584473, 1.3991872072219849, 1.3910354375839233, 1.399137020111084, 1.3902713060379028, 1.3918404579162598, 1.398127794265747, 1.3967254161834717, 1.3953588008880615, 1.3986711502075195, 1.3971214294433594, 1.3986332416534424, 1.3917207717895508, 1.3934935331344604, 1.4034616947174072, 1.3935458660125732, 1.3943772315979004, 1.3921254873275757, 1.39424467086792, 1.398574709892273, 1.3943933248519897, 1.3965882062911987, 1.4052315950393677, 1.4012728929519653, 1.394997239112854, 1.3962234258651733, 1.3995463848114014, 1.3986560106277466, 1.3995277881622314, 1.3963894844055176, 1.3922581672668457, 1.3992133140563965, 1.4032400846481323, 1.39995539188385, 1.4062459468841553, 1.3930822610855103, 1.4041600227355957, 1.4029781818389893, 1.4037222862243652, 1.3937700986862183, 1.4027608633041382, 1.395127296447754, 1.4022703170776367, 1.4094330072402954, 1.40009343624115, 1.4038208723068237, 1.4067920446395874, 1.4032105207443237, 1.4046297073364258, 1.4058667421340942, 1.3950251340866089, 1.407120943069458, 1.403328776359558, 1.4040870666503906, 1.3994483947753906, 1.3935561180114746, 1.3952903747558594, 1.3918648958206177, 1.39902663230896, 1.4008593559265137, 1.3952440023422241, 1.4028769731521606, 1.401233196258545, 1.4005950689315796, 1.4001387357711792, 1.4033896923065186, 1.3977487087249756, 1.3929327726364136, 1.3990259170532227, 1.4061484336853027, 1.4078776836395264, 1.404632329940796, 1.3952034711837769, 1.4020919799804688, 1.408981442451477, 1.3990252017974854, 1.3985453844070435, 1.3983184099197388, 1.4049410820007324, 1.404788851737976, 1.4068583250045776, 1.4115700721740723, 1.4070723056793213, 1.4024745225906372, 1.4032903909683228, 1.4067367315292358, 1.3994901180267334, 1.4073848724365234, 1.406451940536499, 1.409729242324829, 1.4095028638839722, 1.4122240543365479, 1.406288504600525, 1.4042927026748657, 1.3963665962219238, 1.4016488790512085, 1.414462685585022, 1.4024001359939575, 1.4073505401611328, 1.407103180885315, 1.4010305404663086, 1.4034528732299805, 1.4104087352752686, 1.4109957218170166, 1.4047867059707642, 1.4106355905532837, 1.406734585762024, 1.4063986539840698, 1.4053794145584106, 1.4077340364456177, 1.4048782587051392, 1.4060982465744019, 1.405858039855957, 1.4041736125946045, 1.404617428779602, 1.4149545431137085, 1.406085729598999, 1.4038987159729004, 1.4109687805175781, 1.4097416400909424, 1.4185372591018677, 1.4126754999160767, 1.4059597253799438, 1.404450535774231], 'val_accuracy': [0.1817999929189682, 0.3312999904155731, 0.3693000078201294, 0.390500009059906, 0.40939998626708984, 0.4275999963283539, 0.43880000710487366, 0.4498000144958496, 0.454800009727478, 0.4577000141143799, 0.4625000059604645, 0.46560001373291016, 0.4702000021934509, 0.4772000014781952, 0.47589999437332153, 0.47760000824928284, 0.4830999970436096, 0.48750001192092896, 0.4878999888896942, 0.49320000410079956, 0.4918000102043152, 0.4952000081539154, 0.4941999912261963, 0.5005999803543091, 0.4961000084877014, 0.501800000667572, 0.5066999793052673, 0.5120000243186951, 0.5116999745368958, 0.510200023651123, 0.5170999765396118, 0.5098000168800354, 0.5126000046730042, 0.5151000022888184, 0.5166000127792358, 0.5164999961853027, 0.5170999765396118, 0.5163000226020813, 0.5181999802589417, 0.5218999981880188, 0.517300009727478, 0.5166000127792358, 0.5231999754905701, 0.5246000289916992, 0.5239999890327454, 0.5248000025749207, 0.5267999768257141, 0.526199996471405, 0.5274999737739563, 0.5253000259399414, 0.5299999713897705, 0.5300999879837036, 0.5223000049591064, 0.5260999798774719, 0.5238000154495239, 0.526199996471405, 0.5260999798774719, 0.5266000032424927, 0.5315999984741211, 0.5335999727249146, 0.5307000279426575, 0.5267999768257141, 0.5329999923706055, 0.5315999984741211, 0.531499981880188, 0.5327000021934509, 0.5304999947547913, 0.5293999910354614, 0.5253999829292297, 0.5327000021934509, 0.5370000004768372, 0.5375999808311462, 0.5353999733924866, 0.5317999720573425, 0.5339000225067139, 0.5372999906539917, 0.5383999943733215, 0.5343000292778015, 0.536300003528595, 0.5335999727249146, 0.5390999913215637, 0.5397999882698059, 0.5374000072479248, 0.535099983215332, 0.5378999710083008, 0.5351999998092651, 0.5336999893188477, 0.5343999862670898, 0.5375999808311462, 0.5370000004768372, 0.5336999893188477, 0.5414000153541565, 0.5356000065803528, 0.5349000096321106, 0.5404999852180481, 0.5357999801635742, 0.5400000214576721, 0.5383999943733215, 0.5389000177383423, 0.5365999937057495, 0.5386000275611877, 0.5396999716758728, 0.5376999974250793, 0.5353999733924866, 0.5379999876022339, 0.5396999716758728, 0.5400000214576721, 0.5364000201225281, 0.5358999967575073, 0.5383999943733215, 0.5386000275611877, 0.5385000109672546, 0.5432999730110168, 0.536300003528595, 0.536899983882904, 0.5406000018119812, 0.5393000245094299, 0.5407000184059143, 0.5375000238418579, 0.5340999960899353, 0.5403000116348267, 0.5396000146865845, 0.5357000231742859, 0.538100004196167, 0.5322999954223633, 0.5370000004768372, 0.5357000231742859, 0.5368000268936157, 0.5407999753952026, 0.5430999994277954, 0.5425999760627747, 0.5407999753952026, 0.5432000160217285, 0.5449000000953674, 0.5404000282287598, 0.5424000024795532, 0.5444999933242798, 0.5407000184059143, 0.5404000282287598, 0.5393000245094299, 0.5457000136375427, 0.5440000295639038, 0.5407000184059143, 0.5465999841690063, 0.544700026512146, 0.5400000214576721, 0.5389000177383423, 0.541700005531311, 0.5430999994277954, 0.5415999889373779, 0.5357999801635742, 0.5425000190734863, 0.5422000288963318, 0.5440999865531921, 0.5386999845504761, 0.5426999926567078, 0.5432000160217285, 0.5393999814987183, 0.5397999882698059, 0.5442000031471252, 0.542900025844574, 0.5435000061988831, 0.5468000173568726, 0.5414000153541565, 0.5415999889373779, 0.5371000170707703, 0.5383999943733215, 0.5386999845504761, 0.5407000184059143, 0.5396000146865845, 0.5424000024795532, 0.5410000085830688, 0.5407000184059143, 0.5443999767303467, 0.5437999963760376, 0.5414999723434448, 0.5437999963760376, 0.5439000129699707, 0.5360999703407288, 0.5411999821662903, 0.5410000085830688, 0.5392000079154968, 0.5443000197410583, 0.5378999710083008, 0.5388000011444092, 0.5353999733924866, 0.5404999852180481, 0.5425000190734863, 0.5406000018119812, 0.5422000288963318, 0.5396999716758728, 0.5392000079154968, 0.545199990272522, 0.5400000214576721, 0.5414000153541565, 0.541700005531311, 0.5365999937057495, 0.5394999980926514, 0.5412999987602234, 0.5425999760627747]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fEbEqLfADJu"
      },
      "source": [
        "## Question 2\n",
        "\n",
        "Construct a convolutional neural network using your own structure. Try to maximize the prediction accuracy of your model.\n",
        "\n",
        "After the training process, print the training, validation, and test accuracies, as well as plot the training loss and validation loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTrbgdtZknEM"
      },
      "source": [
        "tf.random.set_seed(11)\n",
        "# Load the dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Preprocess\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "y_train = tf.one_hot(y_train, 10)\n",
        "y_test = tf.one_hot(y_test, 10)\n",
        "\n",
        "# Reshape input to be (width, height, #channels)\n",
        "x_train = x_train.reshape((-1,32,32,3))\n",
        "x_test = x_test.reshape((-1,32,32,3))\n",
        "\n",
        "\n",
        "#Normalize the dataset\n",
        "y_train = y_train[:,0,:]\n",
        "y_test = y_test[:,0,:]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eg_bEkwvT0h5",
        "outputId": "581dc6ae-7ac2-4f5c-cb83-b1a653505cba"
      },
      "source": [
        "tf.random.set_seed(11)\n",
        "# Define a model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Input(shape=(32, 32, 3)),\n",
        "    tf.keras.layers.Conv2D(64, (3,3)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.ReLU(),\n",
        "    tf.keras.layers.MaxPooling2D((3,3), strides=(2,2)),\n",
        "    tf.keras.layers.Conv2D(128, (3,3)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.ReLU(),\n",
        "    tf.keras.layers.MaxPooling2D((3,3), strides=(2,2)),\n",
        "    tf.keras.layers.SpatialDropout2D(0.5),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(1e-4)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 30, 30, 64)        1792      \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 30, 30, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " re_lu (ReLU)                (None, 30, 30, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 14, 14, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 12, 12, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 12, 12, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " re_lu_1 (ReLU)              (None, 12, 12, 128)       0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 5, 5, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " spatial_dropout2d (SpatialD  (None, 5, 5, 128)        0         \n",
            " ropout2D)                                                       \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 3200)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 256)               819456    \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 899,466\n",
            "Trainable params: 898,570\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WWT_9hcUMjr",
        "outputId": "28f65dea-3340-464d-b902-480b6485ae8d"
      },
      "source": [
        "# Train the model\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath='/tmp/checkpoint',\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs=200,\n",
        "                    batch_size=512, shuffle = True,\n",
        "                    validation_split=0.2,\n",
        "                    callbacks=[model_checkpoint_callback])\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "79/79 [==============================] - 34s 71ms/step - loss: 1.9103 - accuracy: 0.3823 - val_loss: 2.9161 - val_accuracy: 0.0975\n",
            "Epoch 2/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 1.4742 - accuracy: 0.5041 - val_loss: 3.2929 - val_accuracy: 0.0967\n",
            "Epoch 3/200\n",
            "79/79 [==============================] - 5s 64ms/step - loss: 1.3309 - accuracy: 0.5510 - val_loss: 3.0638 - val_accuracy: 0.1183\n",
            "Epoch 4/200\n",
            "79/79 [==============================] - 5s 64ms/step - loss: 1.2442 - accuracy: 0.5824 - val_loss: 3.0171 - val_accuracy: 0.1505\n",
            "Epoch 5/200\n",
            "79/79 [==============================] - 5s 64ms/step - loss: 1.1796 - accuracy: 0.6088 - val_loss: 2.2696 - val_accuracy: 0.3049\n",
            "Epoch 6/200\n",
            "79/79 [==============================] - 5s 64ms/step - loss: 1.1331 - accuracy: 0.6241 - val_loss: 1.9589 - val_accuracy: 0.3723\n",
            "Epoch 7/200\n",
            "79/79 [==============================] - 5s 64ms/step - loss: 1.0987 - accuracy: 0.6402 - val_loss: 1.3442 - val_accuracy: 0.5394\n",
            "Epoch 8/200\n",
            "79/79 [==============================] - 5s 64ms/step - loss: 1.0602 - accuracy: 0.6496 - val_loss: 1.2338 - val_accuracy: 0.6054\n",
            "Epoch 9/200\n",
            "79/79 [==============================] - 5s 64ms/step - loss: 1.0339 - accuracy: 0.6585 - val_loss: 1.0722 - val_accuracy: 0.6466\n",
            "Epoch 10/200\n",
            "79/79 [==============================] - 5s 64ms/step - loss: 1.0030 - accuracy: 0.6723 - val_loss: 1.0455 - val_accuracy: 0.6525\n",
            "Epoch 11/200\n",
            "79/79 [==============================] - 5s 66ms/step - loss: 0.9880 - accuracy: 0.6782 - val_loss: 1.2061 - val_accuracy: 0.5924\n",
            "Epoch 12/200\n",
            "79/79 [==============================] - 5s 64ms/step - loss: 0.9671 - accuracy: 0.6825 - val_loss: 0.9358 - val_accuracy: 0.6977\n",
            "Epoch 13/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.9527 - accuracy: 0.6888 - val_loss: 0.9006 - val_accuracy: 0.7154\n",
            "Epoch 14/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.9216 - accuracy: 0.7014 - val_loss: 0.9391 - val_accuracy: 0.7005\n",
            "Epoch 15/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.9040 - accuracy: 0.7061 - val_loss: 0.9320 - val_accuracy: 0.7004\n",
            "Epoch 16/200\n",
            "79/79 [==============================] - 5s 64ms/step - loss: 0.8906 - accuracy: 0.7136 - val_loss: 0.8648 - val_accuracy: 0.7268\n",
            "Epoch 17/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.8749 - accuracy: 0.7175 - val_loss: 1.0446 - val_accuracy: 0.6673\n",
            "Epoch 18/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.8644 - accuracy: 0.7214 - val_loss: 0.8957 - val_accuracy: 0.7193\n",
            "Epoch 19/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.8522 - accuracy: 0.7251 - val_loss: 1.0235 - val_accuracy: 0.6728\n",
            "Epoch 20/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.8316 - accuracy: 0.7356 - val_loss: 0.9232 - val_accuracy: 0.7065\n",
            "Epoch 21/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.8255 - accuracy: 0.7371 - val_loss: 1.1099 - val_accuracy: 0.6366\n",
            "Epoch 22/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.8092 - accuracy: 0.7426 - val_loss: 1.0341 - val_accuracy: 0.6789\n",
            "Epoch 23/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.7973 - accuracy: 0.7461 - val_loss: 0.8658 - val_accuracy: 0.7368\n",
            "Epoch 24/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.7708 - accuracy: 0.7566 - val_loss: 0.8898 - val_accuracy: 0.7264\n",
            "Epoch 25/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.7659 - accuracy: 0.7577 - val_loss: 1.0427 - val_accuracy: 0.6600\n",
            "Epoch 26/200\n",
            "79/79 [==============================] - 5s 64ms/step - loss: 0.7630 - accuracy: 0.7613 - val_loss: 0.8191 - val_accuracy: 0.7486\n",
            "Epoch 27/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.7455 - accuracy: 0.7681 - val_loss: 0.9049 - val_accuracy: 0.7172\n",
            "Epoch 28/200\n",
            "79/79 [==============================] - 5s 66ms/step - loss: 0.7401 - accuracy: 0.7700 - val_loss: 0.8106 - val_accuracy: 0.7477\n",
            "Epoch 29/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.7289 - accuracy: 0.7760 - val_loss: 0.8871 - val_accuracy: 0.7305\n",
            "Epoch 30/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.7170 - accuracy: 0.7778 - val_loss: 0.8638 - val_accuracy: 0.7367\n",
            "Epoch 31/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.7133 - accuracy: 0.7825 - val_loss: 0.8279 - val_accuracy: 0.7485\n",
            "Epoch 32/200\n",
            "79/79 [==============================] - 5s 64ms/step - loss: 0.6998 - accuracy: 0.7862 - val_loss: 0.8052 - val_accuracy: 0.7561\n",
            "Epoch 33/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.6980 - accuracy: 0.7864 - val_loss: 0.8126 - val_accuracy: 0.7512\n",
            "Epoch 34/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.6856 - accuracy: 0.7921 - val_loss: 0.9038 - val_accuracy: 0.7280\n",
            "Epoch 35/200\n",
            "79/79 [==============================] - 5s 64ms/step - loss: 0.6784 - accuracy: 0.7939 - val_loss: 0.8120 - val_accuracy: 0.7567\n",
            "Epoch 36/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.6732 - accuracy: 0.7978 - val_loss: 0.8168 - val_accuracy: 0.7526\n",
            "Epoch 37/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.6681 - accuracy: 0.8002 - val_loss: 0.9076 - val_accuracy: 0.7212\n",
            "Epoch 38/200\n",
            "79/79 [==============================] - 5s 64ms/step - loss: 0.6691 - accuracy: 0.7987 - val_loss: 0.8695 - val_accuracy: 0.7368\n",
            "Epoch 39/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.6541 - accuracy: 0.8065 - val_loss: 0.8946 - val_accuracy: 0.7278\n",
            "Epoch 40/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.6477 - accuracy: 0.8088 - val_loss: 0.8312 - val_accuracy: 0.7576\n",
            "Epoch 41/200\n",
            "79/79 [==============================] - 5s 64ms/step - loss: 0.6441 - accuracy: 0.8104 - val_loss: 0.8010 - val_accuracy: 0.7625\n",
            "Epoch 42/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.6441 - accuracy: 0.8115 - val_loss: 0.8018 - val_accuracy: 0.7617\n",
            "Epoch 43/200\n",
            "79/79 [==============================] - 5s 64ms/step - loss: 0.6342 - accuracy: 0.8138 - val_loss: 0.7923 - val_accuracy: 0.7657\n",
            "Epoch 44/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.6169 - accuracy: 0.8211 - val_loss: 0.8123 - val_accuracy: 0.7640\n",
            "Epoch 45/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.6080 - accuracy: 0.8250 - val_loss: 1.0209 - val_accuracy: 0.7051\n",
            "Epoch 46/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.6175 - accuracy: 0.8213 - val_loss: 0.7695 - val_accuracy: 0.7745\n",
            "Epoch 47/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.6148 - accuracy: 0.8244 - val_loss: 0.8167 - val_accuracy: 0.7630\n",
            "Epoch 48/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.6017 - accuracy: 0.8278 - val_loss: 0.8658 - val_accuracy: 0.7452\n",
            "Epoch 49/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.5979 - accuracy: 0.8299 - val_loss: 0.8139 - val_accuracy: 0.7656\n",
            "Epoch 50/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.5939 - accuracy: 0.8326 - val_loss: 0.8244 - val_accuracy: 0.7580\n",
            "Epoch 51/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.5850 - accuracy: 0.8368 - val_loss: 0.8974 - val_accuracy: 0.7424\n",
            "Epoch 52/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.5831 - accuracy: 0.8373 - val_loss: 0.9350 - val_accuracy: 0.7218\n",
            "Epoch 53/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.5926 - accuracy: 0.8357 - val_loss: 0.8399 - val_accuracy: 0.7571\n",
            "Epoch 54/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.5805 - accuracy: 0.8400 - val_loss: 0.8479 - val_accuracy: 0.7599\n",
            "Epoch 55/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.5746 - accuracy: 0.8428 - val_loss: 0.8428 - val_accuracy: 0.7622\n",
            "Epoch 56/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.5792 - accuracy: 0.8424 - val_loss: 0.8377 - val_accuracy: 0.7593\n",
            "Epoch 57/200\n",
            "79/79 [==============================] - 5s 61ms/step - loss: 0.5711 - accuracy: 0.8415 - val_loss: 0.8007 - val_accuracy: 0.7671\n",
            "Epoch 58/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.5617 - accuracy: 0.8446 - val_loss: 0.8118 - val_accuracy: 0.7742\n",
            "Epoch 59/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.5567 - accuracy: 0.8487 - val_loss: 0.8713 - val_accuracy: 0.7521\n",
            "Epoch 60/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.5677 - accuracy: 0.8461 - val_loss: 0.9147 - val_accuracy: 0.7379\n",
            "Epoch 61/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.5601 - accuracy: 0.8510 - val_loss: 0.8406 - val_accuracy: 0.7577\n",
            "Epoch 62/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.5610 - accuracy: 0.8496 - val_loss: 0.8088 - val_accuracy: 0.7696\n",
            "Epoch 63/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.5618 - accuracy: 0.8494 - val_loss: 0.8517 - val_accuracy: 0.7571\n",
            "Epoch 64/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.5550 - accuracy: 0.8499 - val_loss: 0.8726 - val_accuracy: 0.7525\n",
            "Epoch 65/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.5445 - accuracy: 0.8561 - val_loss: 0.8205 - val_accuracy: 0.7680\n",
            "Epoch 66/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.5440 - accuracy: 0.8588 - val_loss: 0.8538 - val_accuracy: 0.7614\n",
            "Epoch 67/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.5300 - accuracy: 0.8605 - val_loss: 0.8786 - val_accuracy: 0.7443\n",
            "Epoch 68/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.5384 - accuracy: 0.8577 - val_loss: 0.9078 - val_accuracy: 0.7492\n",
            "Epoch 69/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.5279 - accuracy: 0.8622 - val_loss: 0.8164 - val_accuracy: 0.7706\n",
            "Epoch 70/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.5361 - accuracy: 0.8597 - val_loss: 0.8609 - val_accuracy: 0.7599\n",
            "Epoch 71/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.5348 - accuracy: 0.8607 - val_loss: 0.8321 - val_accuracy: 0.7725\n",
            "Epoch 72/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.5311 - accuracy: 0.8637 - val_loss: 0.8524 - val_accuracy: 0.7579\n",
            "Epoch 73/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.5334 - accuracy: 0.8622 - val_loss: 0.8733 - val_accuracy: 0.7553\n",
            "Epoch 74/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.5292 - accuracy: 0.8652 - val_loss: 0.8080 - val_accuracy: 0.7755\n",
            "Epoch 75/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.5369 - accuracy: 0.8618 - val_loss: 0.8346 - val_accuracy: 0.7691\n",
            "Epoch 76/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.5223 - accuracy: 0.8673 - val_loss: 0.9579 - val_accuracy: 0.7314\n",
            "Epoch 77/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.5207 - accuracy: 0.8657 - val_loss: 0.8530 - val_accuracy: 0.7623\n",
            "Epoch 78/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.5282 - accuracy: 0.8642 - val_loss: 0.9069 - val_accuracy: 0.7448\n",
            "Epoch 79/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.5196 - accuracy: 0.8686 - val_loss: 0.8957 - val_accuracy: 0.7548\n",
            "Epoch 80/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.5110 - accuracy: 0.8732 - val_loss: 0.8258 - val_accuracy: 0.7700\n",
            "Epoch 81/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.5144 - accuracy: 0.8699 - val_loss: 0.8202 - val_accuracy: 0.7727\n",
            "Epoch 82/200\n",
            "79/79 [==============================] - 5s 66ms/step - loss: 0.5105 - accuracy: 0.8703 - val_loss: 0.8637 - val_accuracy: 0.7651\n",
            "Epoch 83/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.5093 - accuracy: 0.8720 - val_loss: 0.8183 - val_accuracy: 0.7764\n",
            "Epoch 84/200\n",
            "79/79 [==============================] - 5s 66ms/step - loss: 0.4977 - accuracy: 0.8774 - val_loss: 1.0325 - val_accuracy: 0.7164\n",
            "Epoch 85/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.5087 - accuracy: 0.8722 - val_loss: 0.8848 - val_accuracy: 0.7533\n",
            "Epoch 86/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.5102 - accuracy: 0.8730 - val_loss: 0.8423 - val_accuracy: 0.7721\n",
            "Epoch 87/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.4996 - accuracy: 0.8776 - val_loss: 0.8885 - val_accuracy: 0.7587\n",
            "Epoch 88/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.5018 - accuracy: 0.8767 - val_loss: 0.8291 - val_accuracy: 0.7742\n",
            "Epoch 89/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.4950 - accuracy: 0.8795 - val_loss: 0.8050 - val_accuracy: 0.7783\n",
            "Epoch 90/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.4947 - accuracy: 0.8781 - val_loss: 0.8652 - val_accuracy: 0.7687\n",
            "Epoch 91/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.4935 - accuracy: 0.8795 - val_loss: 0.8180 - val_accuracy: 0.7791\n",
            "Epoch 92/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.4936 - accuracy: 0.8795 - val_loss: 0.8250 - val_accuracy: 0.7773\n",
            "Epoch 93/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.4990 - accuracy: 0.8776 - val_loss: 0.7974 - val_accuracy: 0.7831\n",
            "Epoch 94/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.4867 - accuracy: 0.8827 - val_loss: 0.9396 - val_accuracy: 0.7392\n",
            "Epoch 95/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.5145 - accuracy: 0.8726 - val_loss: 0.8637 - val_accuracy: 0.7691\n",
            "Epoch 96/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.4952 - accuracy: 0.8797 - val_loss: 0.8667 - val_accuracy: 0.7646\n",
            "Epoch 97/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.4968 - accuracy: 0.8813 - val_loss: 0.8400 - val_accuracy: 0.7760\n",
            "Epoch 98/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.4890 - accuracy: 0.8836 - val_loss: 0.8410 - val_accuracy: 0.7726\n",
            "Epoch 99/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.4930 - accuracy: 0.8837 - val_loss: 0.8358 - val_accuracy: 0.7759\n",
            "Epoch 100/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.4981 - accuracy: 0.8792 - val_loss: 1.0109 - val_accuracy: 0.7418\n",
            "Epoch 101/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.4905 - accuracy: 0.8833 - val_loss: 0.8164 - val_accuracy: 0.7817\n",
            "Epoch 102/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.4959 - accuracy: 0.8815 - val_loss: 0.8249 - val_accuracy: 0.7762\n",
            "Epoch 103/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.4849 - accuracy: 0.8849 - val_loss: 0.8457 - val_accuracy: 0.7692\n",
            "Epoch 104/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.4841 - accuracy: 0.8853 - val_loss: 0.8224 - val_accuracy: 0.7777\n",
            "Epoch 105/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.4823 - accuracy: 0.8845 - val_loss: 0.8319 - val_accuracy: 0.7750\n",
            "Epoch 106/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.4773 - accuracy: 0.8868 - val_loss: 0.8582 - val_accuracy: 0.7675\n",
            "Epoch 107/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.4782 - accuracy: 0.8874 - val_loss: 0.8247 - val_accuracy: 0.7777\n",
            "Epoch 108/200\n",
            "79/79 [==============================] - 5s 66ms/step - loss: 0.4843 - accuracy: 0.8863 - val_loss: 0.8274 - val_accuracy: 0.7739\n",
            "Epoch 109/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.4793 - accuracy: 0.8874 - val_loss: 0.8519 - val_accuracy: 0.7766\n",
            "Epoch 110/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.4709 - accuracy: 0.8914 - val_loss: 0.8651 - val_accuracy: 0.7706\n",
            "Epoch 111/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.4834 - accuracy: 0.8857 - val_loss: 0.8158 - val_accuracy: 0.7841\n",
            "Epoch 112/200\n",
            "79/79 [==============================] - 5s 64ms/step - loss: 0.4778 - accuracy: 0.8890 - val_loss: 0.8888 - val_accuracy: 0.7604\n",
            "Epoch 113/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.4747 - accuracy: 0.8907 - val_loss: 0.8375 - val_accuracy: 0.7806\n",
            "Epoch 114/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.4706 - accuracy: 0.8914 - val_loss: 0.8571 - val_accuracy: 0.7736\n",
            "Epoch 115/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.4701 - accuracy: 0.8909 - val_loss: 0.8475 - val_accuracy: 0.7737\n",
            "Epoch 116/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.4582 - accuracy: 0.8969 - val_loss: 0.8263 - val_accuracy: 0.7786\n",
            "Epoch 117/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.4750 - accuracy: 0.8910 - val_loss: 0.8483 - val_accuracy: 0.7758\n",
            "Epoch 118/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.4719 - accuracy: 0.8899 - val_loss: 0.8550 - val_accuracy: 0.7744\n",
            "Epoch 119/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.4711 - accuracy: 0.8914 - val_loss: 0.8297 - val_accuracy: 0.7818\n",
            "Epoch 120/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.4681 - accuracy: 0.8939 - val_loss: 0.8511 - val_accuracy: 0.7723\n",
            "Epoch 121/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.4672 - accuracy: 0.8937 - val_loss: 0.8237 - val_accuracy: 0.7829\n",
            "Epoch 122/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.4698 - accuracy: 0.8912 - val_loss: 0.8474 - val_accuracy: 0.7770\n",
            "Epoch 123/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.4746 - accuracy: 0.8901 - val_loss: 0.8494 - val_accuracy: 0.7818\n",
            "Epoch 124/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.4677 - accuracy: 0.8933 - val_loss: 0.8437 - val_accuracy: 0.7713\n",
            "Epoch 125/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.4705 - accuracy: 0.8921 - val_loss: 0.8589 - val_accuracy: 0.7761\n",
            "Epoch 126/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.4685 - accuracy: 0.8929 - val_loss: 0.8873 - val_accuracy: 0.7666\n",
            "Epoch 127/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.4658 - accuracy: 0.8934 - val_loss: 0.8456 - val_accuracy: 0.7782\n",
            "Epoch 128/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.4598 - accuracy: 0.8956 - val_loss: 0.9026 - val_accuracy: 0.7590\n",
            "Epoch 129/200\n",
            "79/79 [==============================] - 5s 61ms/step - loss: 0.4626 - accuracy: 0.8957 - val_loss: 0.8998 - val_accuracy: 0.7568\n",
            "Epoch 130/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.4505 - accuracy: 0.8985 - val_loss: 0.8579 - val_accuracy: 0.7793\n",
            "Epoch 131/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.4622 - accuracy: 0.8949 - val_loss: 0.9463 - val_accuracy: 0.7516\n",
            "Epoch 132/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.4653 - accuracy: 0.8937 - val_loss: 0.8615 - val_accuracy: 0.7708\n",
            "Epoch 133/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.4567 - accuracy: 0.8968 - val_loss: 0.8439 - val_accuracy: 0.7778\n",
            "Epoch 134/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.4608 - accuracy: 0.8952 - val_loss: 0.9142 - val_accuracy: 0.7567\n",
            "Epoch 135/200\n",
            "79/79 [==============================] - 5s 65ms/step - loss: 0.4667 - accuracy: 0.8956 - val_loss: 0.8451 - val_accuracy: 0.7749\n",
            "Epoch 136/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.4572 - accuracy: 0.8965 - val_loss: 0.8532 - val_accuracy: 0.7770\n",
            "Epoch 137/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.4581 - accuracy: 0.8981 - val_loss: 0.8212 - val_accuracy: 0.7841\n",
            "Epoch 138/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.4639 - accuracy: 0.8950 - val_loss: 0.8709 - val_accuracy: 0.7724\n",
            "Epoch 139/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.4598 - accuracy: 0.8952 - val_loss: 0.8310 - val_accuracy: 0.7865\n",
            "Epoch 140/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.4671 - accuracy: 0.8965 - val_loss: 0.8527 - val_accuracy: 0.7783\n",
            "Epoch 141/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.4627 - accuracy: 0.8961 - val_loss: 0.8492 - val_accuracy: 0.7763\n",
            "Epoch 142/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.4598 - accuracy: 0.8974 - val_loss: 0.8487 - val_accuracy: 0.7812\n",
            "Epoch 143/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.4613 - accuracy: 0.8970 - val_loss: 0.8844 - val_accuracy: 0.7671\n",
            "Epoch 144/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.4475 - accuracy: 0.9003 - val_loss: 0.8201 - val_accuracy: 0.7901\n",
            "Epoch 145/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.4523 - accuracy: 0.9002 - val_loss: 0.8188 - val_accuracy: 0.7851\n",
            "Epoch 146/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.4538 - accuracy: 0.9007 - val_loss: 0.9117 - val_accuracy: 0.7613\n",
            "Epoch 147/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.4456 - accuracy: 0.9021 - val_loss: 0.8304 - val_accuracy: 0.7832\n",
            "Epoch 148/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.4503 - accuracy: 0.9006 - val_loss: 0.8741 - val_accuracy: 0.7750\n",
            "Epoch 149/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.4425 - accuracy: 0.9046 - val_loss: 0.8527 - val_accuracy: 0.7745\n",
            "Epoch 150/200\n",
            "79/79 [==============================] - 5s 61ms/step - loss: 0.4509 - accuracy: 0.9002 - val_loss: 0.8745 - val_accuracy: 0.7674\n",
            "Epoch 151/200\n",
            "79/79 [==============================] - 5s 61ms/step - loss: 0.4643 - accuracy: 0.8958 - val_loss: 0.8282 - val_accuracy: 0.7806\n",
            "Epoch 152/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.4497 - accuracy: 0.9004 - val_loss: 0.8993 - val_accuracy: 0.7588\n",
            "Epoch 153/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.4579 - accuracy: 0.8973 - val_loss: 0.8595 - val_accuracy: 0.7770\n",
            "Epoch 154/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.4510 - accuracy: 0.9010 - val_loss: 0.9446 - val_accuracy: 0.7584\n",
            "Epoch 155/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.4414 - accuracy: 0.9051 - val_loss: 0.8297 - val_accuracy: 0.7818\n",
            "Epoch 156/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.4403 - accuracy: 0.9029 - val_loss: 0.8508 - val_accuracy: 0.7765\n",
            "Epoch 157/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.4314 - accuracy: 0.9070 - val_loss: 0.8290 - val_accuracy: 0.7829\n",
            "Epoch 158/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.4460 - accuracy: 0.9017 - val_loss: 0.8374 - val_accuracy: 0.7815\n",
            "Epoch 159/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.4521 - accuracy: 0.9015 - val_loss: 0.9618 - val_accuracy: 0.7522\n",
            "Epoch 160/200\n",
            "79/79 [==============================] - 5s 61ms/step - loss: 0.4388 - accuracy: 0.9044 - val_loss: 0.8462 - val_accuracy: 0.7794\n",
            "Epoch 161/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.4337 - accuracy: 0.9071 - val_loss: 0.8157 - val_accuracy: 0.7870\n",
            "Epoch 162/200\n",
            "79/79 [==============================] - 5s 61ms/step - loss: 0.4381 - accuracy: 0.9032 - val_loss: 0.8706 - val_accuracy: 0.7744\n",
            "Epoch 163/200\n",
            "79/79 [==============================] - 5s 61ms/step - loss: 0.4372 - accuracy: 0.9041 - val_loss: 0.9023 - val_accuracy: 0.7614\n",
            "Epoch 164/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.4451 - accuracy: 0.9021 - val_loss: 0.8316 - val_accuracy: 0.7834\n",
            "Epoch 165/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.4378 - accuracy: 0.9054 - val_loss: 0.8418 - val_accuracy: 0.7845\n",
            "Epoch 166/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.4425 - accuracy: 0.9050 - val_loss: 0.8545 - val_accuracy: 0.7767\n",
            "Epoch 167/200\n",
            "79/79 [==============================] - 5s 61ms/step - loss: 0.4301 - accuracy: 0.9079 - val_loss: 0.8880 - val_accuracy: 0.7635\n",
            "Epoch 168/200\n",
            "79/79 [==============================] - 5s 61ms/step - loss: 0.4324 - accuracy: 0.9064 - val_loss: 0.8360 - val_accuracy: 0.7873\n",
            "Epoch 169/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.4308 - accuracy: 0.9080 - val_loss: 0.8270 - val_accuracy: 0.7905\n",
            "Epoch 170/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.4363 - accuracy: 0.9062 - val_loss: 0.8788 - val_accuracy: 0.7740\n",
            "Epoch 171/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.4298 - accuracy: 0.9082 - val_loss: 0.8785 - val_accuracy: 0.7700\n",
            "Epoch 172/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.4355 - accuracy: 0.9057 - val_loss: 0.8368 - val_accuracy: 0.7881\n",
            "Epoch 173/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.4427 - accuracy: 0.9048 - val_loss: 0.8366 - val_accuracy: 0.7845\n",
            "Epoch 174/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.4377 - accuracy: 0.9049 - val_loss: 0.8980 - val_accuracy: 0.7662\n",
            "Epoch 175/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.4391 - accuracy: 0.9062 - val_loss: 0.8441 - val_accuracy: 0.7812\n",
            "Epoch 176/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.4574 - accuracy: 0.8985 - val_loss: 0.9035 - val_accuracy: 0.7655\n",
            "Epoch 177/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.4445 - accuracy: 0.9039 - val_loss: 0.8953 - val_accuracy: 0.7726\n",
            "Epoch 178/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.4458 - accuracy: 0.9035 - val_loss: 0.8470 - val_accuracy: 0.7792\n",
            "Epoch 179/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.4356 - accuracy: 0.9055 - val_loss: 0.8639 - val_accuracy: 0.7770\n",
            "Epoch 180/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.4265 - accuracy: 0.9079 - val_loss: 0.9240 - val_accuracy: 0.7619\n",
            "Epoch 181/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.4460 - accuracy: 0.9035 - val_loss: 0.9330 - val_accuracy: 0.7564\n",
            "Epoch 182/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.4324 - accuracy: 0.9059 - val_loss: 0.8750 - val_accuracy: 0.7745\n",
            "Epoch 183/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.4369 - accuracy: 0.9075 - val_loss: 0.8901 - val_accuracy: 0.7671\n",
            "Epoch 184/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.4339 - accuracy: 0.9081 - val_loss: 0.8810 - val_accuracy: 0.7740\n",
            "Epoch 185/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.4336 - accuracy: 0.9069 - val_loss: 0.8433 - val_accuracy: 0.7805\n",
            "Epoch 186/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.4337 - accuracy: 0.9075 - val_loss: 0.8440 - val_accuracy: 0.7870\n",
            "Epoch 187/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.4292 - accuracy: 0.9090 - val_loss: 0.9256 - val_accuracy: 0.7652\n",
            "Epoch 188/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.4217 - accuracy: 0.9108 - val_loss: 0.8509 - val_accuracy: 0.7797\n",
            "Epoch 189/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.4252 - accuracy: 0.9100 - val_loss: 0.8969 - val_accuracy: 0.7720\n",
            "Epoch 190/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.4299 - accuracy: 0.9079 - val_loss: 0.8565 - val_accuracy: 0.7762\n",
            "Epoch 191/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.4281 - accuracy: 0.9083 - val_loss: 0.8613 - val_accuracy: 0.7790\n",
            "Epoch 192/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.4303 - accuracy: 0.9063 - val_loss: 0.8513 - val_accuracy: 0.7824\n",
            "Epoch 193/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.4344 - accuracy: 0.9071 - val_loss: 0.8909 - val_accuracy: 0.7735\n",
            "Epoch 194/200\n",
            "79/79 [==============================] - 5s 64ms/step - loss: 0.4312 - accuracy: 0.9092 - val_loss: 0.8283 - val_accuracy: 0.7925\n",
            "Epoch 195/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.4245 - accuracy: 0.9112 - val_loss: 0.8567 - val_accuracy: 0.7817\n",
            "Epoch 196/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.4244 - accuracy: 0.9099 - val_loss: 0.8583 - val_accuracy: 0.7816\n",
            "Epoch 197/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.4284 - accuracy: 0.9074 - val_loss: 0.8145 - val_accuracy: 0.7947\n",
            "Epoch 198/200\n",
            "79/79 [==============================] - 5s 62ms/step - loss: 0.4218 - accuracy: 0.9112 - val_loss: 0.8838 - val_accuracy: 0.7742\n",
            "Epoch 199/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.4268 - accuracy: 0.9093 - val_loss: 0.9249 - val_accuracy: 0.7648\n",
            "Epoch 200/200\n",
            "79/79 [==============================] - 5s 63ms/step - loss: 0.4199 - accuracy: 0.9129 - val_loss: 0.8462 - val_accuracy: 0.7825\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGk4Tv5cS5xL",
        "outputId": "712cf9a0-c118-4994-b635-c111c289f287"
      },
      "source": [
        "\n",
        "print(\"Training Accuracy\")\n",
        "print(model.evaluate(x_train, y_train, verbose=0))\n",
        "\n",
        "\n",
        "print(\"Test Accuracy\")\n",
        "print(model.evaluate(x_test, y_test, verbose=0))\n",
        "\n",
        "\n",
        "#Print Training History\n",
        "print(history.history)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy\n",
            "[0.3549463152885437, 0.9505599737167358]\n",
            "Test Accuracy\n",
            "[0.8449485301971436, 0.77920001745224]\n",
            "{'loss': [1.9102667570114136, 1.4742317199707031, 1.3309202194213867, 1.2442190647125244, 1.1796143054962158, 1.1331473588943481, 1.0987190008163452, 1.060181975364685, 1.0338506698608398, 1.0030226707458496, 0.9879653453826904, 0.9671393632888794, 0.952724814414978, 0.9216055870056152, 0.9040008783340454, 0.8906147480010986, 0.8749070167541504, 0.8643665909767151, 0.8521974682807922, 0.8316007852554321, 0.8255022168159485, 0.8092015981674194, 0.797347903251648, 0.7708078026771545, 0.7658625245094299, 0.763022243976593, 0.7454783916473389, 0.7400557994842529, 0.7289069890975952, 0.7169638872146606, 0.7133325338363647, 0.6997507810592651, 0.6980090141296387, 0.6856001019477844, 0.678419828414917, 0.6731963753700256, 0.6680532693862915, 0.6690765619277954, 0.6541242003440857, 0.6477046608924866, 0.6441466808319092, 0.644120454788208, 0.6342241764068604, 0.6169238686561584, 0.6079943776130676, 0.6175059080123901, 0.6148034930229187, 0.6017459630966187, 0.5978916883468628, 0.5938727259635925, 0.5850425958633423, 0.583137035369873, 0.5925942659378052, 0.5805174112319946, 0.5745511651039124, 0.5792326927185059, 0.571126401424408, 0.5616871118545532, 0.556725025177002, 0.5676804780960083, 0.5600576400756836, 0.5609828233718872, 0.5617830157279968, 0.5550471544265747, 0.5444956421852112, 0.5440383553504944, 0.5300043225288391, 0.5383799076080322, 0.5279009342193604, 0.5361080765724182, 0.534778892993927, 0.5310768485069275, 0.5333573222160339, 0.5291571617126465, 0.5369473695755005, 0.5223015546798706, 0.5207144021987915, 0.528248131275177, 0.5195852518081665, 0.5109903216362, 0.5144196152687073, 0.5104820132255554, 0.509306788444519, 0.4977099597454071, 0.5087049603462219, 0.5102055668830872, 0.4996451139450073, 0.5017897486686707, 0.49503105878829956, 0.4947148561477661, 0.49354830384254456, 0.4936131238937378, 0.49899500608444214, 0.48670318722724915, 0.5144782066345215, 0.49522528052330017, 0.4968256950378418, 0.4889620542526245, 0.4929961562156677, 0.4981435537338257, 0.49049532413482666, 0.49590352177619934, 0.4848673939704895, 0.4841095805168152, 0.48229852318763733, 0.4773002862930298, 0.47817176580429077, 0.4842812120914459, 0.4792576730251312, 0.47093433141708374, 0.4834063947200775, 0.4777727425098419, 0.47465386986732483, 0.47061049938201904, 0.4700607359409332, 0.4582348167896271, 0.4749963879585266, 0.4719134271144867, 0.4710997939109802, 0.4680749475955963, 0.4671545922756195, 0.46984100341796875, 0.4746174216270447, 0.4676666855812073, 0.47049736976623535, 0.4685438573360443, 0.4658015966415405, 0.45979970693588257, 0.46258774399757385, 0.4504624009132385, 0.46216845512390137, 0.4653013050556183, 0.4567224085330963, 0.4608401358127594, 0.4666566550731659, 0.4572148025035858, 0.4581347107887268, 0.4639393091201782, 0.4597696363925934, 0.4670989215373993, 0.4626622498035431, 0.4598211944103241, 0.4613368511199951, 0.4474667012691498, 0.4522853493690491, 0.4537920355796814, 0.4455970823764801, 0.45032167434692383, 0.442469984292984, 0.4509131908416748, 0.4643310010433197, 0.44971147179603577, 0.45790618658065796, 0.4509674906730652, 0.4414201080799103, 0.4402674734592438, 0.4313584864139557, 0.4460444748401642, 0.45214882493019104, 0.4387829005718231, 0.4337345361709595, 0.43807852268218994, 0.4371701180934906, 0.4451192021369934, 0.4377726912498474, 0.4424901306629181, 0.4300609230995178, 0.4324057102203369, 0.4307861328125, 0.43629327416419983, 0.42975082993507385, 0.43553638458251953, 0.4427117109298706, 0.43768975138664246, 0.43909409642219543, 0.45741981267929077, 0.44454360008239746, 0.445774108171463, 0.4356192946434021, 0.4265088438987732, 0.4459517002105713, 0.43240106105804443, 0.43687704205513, 0.43387293815612793, 0.43364471197128296, 0.4337256848812103, 0.42921292781829834, 0.42166265845298767, 0.42519161105155945, 0.429866224527359, 0.42805176973342896, 0.43029144406318665, 0.4344105124473572, 0.4312025308609009, 0.4245249629020691, 0.4244260787963867, 0.42840760946273804, 0.42179301381111145, 0.4268469214439392, 0.41987913846969604], 'accuracy': [0.3822749853134155, 0.5041499733924866, 0.5509750247001648, 0.5824000239372253, 0.6088250279426575, 0.6241250038146973, 0.6401749849319458, 0.6495500206947327, 0.6585249900817871, 0.6722999811172485, 0.6782000064849854, 0.6825000047683716, 0.6888499855995178, 0.7014250159263611, 0.7060999870300293, 0.713575005531311, 0.7174749970436096, 0.7213500142097473, 0.7250999808311462, 0.7355750203132629, 0.7371000051498413, 0.7425749897956848, 0.7461000084877014, 0.7565500140190125, 0.7577499747276306, 0.7612749934196472, 0.7680749893188477, 0.7699999809265137, 0.7760000228881836, 0.7777500152587891, 0.7825499773025513, 0.7861999869346619, 0.7863500118255615, 0.7921000123023987, 0.7938500046730042, 0.7977749705314636, 0.8001750111579895, 0.7986999750137329, 0.8064749836921692, 0.808775007724762, 0.8103749752044678, 0.8114749789237976, 0.8138499855995178, 0.8210999965667725, 0.8250499963760376, 0.8213000297546387, 0.8243749737739563, 0.8278499841690063, 0.8298500180244446, 0.8325999975204468, 0.8368250131607056, 0.8372750282287598, 0.8356750011444092, 0.840025007724762, 0.8427500128746033, 0.8424249887466431, 0.8414750099182129, 0.8446000218391418, 0.8486999869346619, 0.8460999727249146, 0.8509500026702881, 0.8496000170707703, 0.8494499921798706, 0.8499000072479248, 0.8560500144958496, 0.8587999939918518, 0.8604750037193298, 0.8577250242233276, 0.8622000217437744, 0.8596749901771545, 0.8606749773025513, 0.8636500239372253, 0.8621749877929688, 0.8651750087738037, 0.8618249893188477, 0.8672999739646912, 0.8656749725341797, 0.8641999959945679, 0.8685500025749207, 0.873199999332428, 0.8698750138282776, 0.8703250288963318, 0.8720499873161316, 0.8774499893188477, 0.8721500039100647, 0.8730000257492065, 0.8775749802589417, 0.8767499923706055, 0.8794500231742859, 0.8781499862670898, 0.8794500231742859, 0.8794749975204468, 0.8776249885559082, 0.8827000260353088, 0.8725749850273132, 0.8796749711036682, 0.8813499808311462, 0.8835999965667725, 0.8837249875068665, 0.8792499899864197, 0.8832749724388123, 0.8814749717712402, 0.8849250078201294, 0.885325014591217, 0.8845499753952026, 0.8867999911308289, 0.8874499797821045, 0.8862500190734863, 0.887374997138977, 0.8913999795913696, 0.8857499957084656, 0.8889750242233276, 0.8907250165939331, 0.8913750052452087, 0.8908500075340271, 0.8969249725341797, 0.8909749984741211, 0.8898500204086304, 0.8914499878883362, 0.8939250111579895, 0.8937249779701233, 0.8911749720573425, 0.8901249766349792, 0.8932750225067139, 0.8920750021934509, 0.8929499983787537, 0.8933500051498413, 0.8956249952316284, 0.895675003528595, 0.8985499739646912, 0.8949499726295471, 0.8936750292778015, 0.8967999815940857, 0.8952249884605408, 0.8956000208854675, 0.8964750170707703, 0.8981000185012817, 0.8949750065803528, 0.8952249884605408, 0.8965499997138977, 0.8961250185966492, 0.8974249958992004, 0.8970249891281128, 0.9002749919891357, 0.9002249836921692, 0.9007250070571899, 0.9020500183105469, 0.9006249904632568, 0.9046000242233276, 0.9002249836921692, 0.895799994468689, 0.9003750085830688, 0.8973249793052673, 0.900950014591217, 0.9051250219345093, 0.902899980545044, 0.9070000052452087, 0.9016749858856201, 0.9015499949455261, 0.9044250249862671, 0.9071000218391418, 0.9031500220298767, 0.9041249752044678, 0.9021000266075134, 0.9053999781608582, 0.9049749970436096, 0.907925009727478, 0.9064499735832214, 0.9079999923706055, 0.9061999917030334, 0.908174991607666, 0.9057499766349792, 0.9047750234603882, 0.9049249887466431, 0.9061999917030334, 0.8985499739646912, 0.9038749933242798, 0.9034500122070312, 0.9054999947547913, 0.907925009727478, 0.9035000205039978, 0.905875027179718, 0.9074500203132629, 0.9081000089645386, 0.9068750143051147, 0.9075000286102295, 0.9089750051498413, 0.9107999801635742, 0.909974992275238, 0.9079499840736389, 0.9083499908447266, 0.9063000082969666, 0.9070500135421753, 0.9092249870300293, 0.911175012588501, 0.9099249839782715, 0.9074000120162964, 0.9112499952316284, 0.9093250036239624, 0.912850022315979], 'val_loss': [2.916130304336548, 3.2929210662841797, 3.0637640953063965, 3.017108678817749, 2.2696261405944824, 1.9589160680770874, 1.3441684246063232, 1.2338460683822632, 1.0721889734268188, 1.0454756021499634, 1.2061349153518677, 0.9357510805130005, 0.9006165266036987, 0.939132809638977, 0.9319563508033752, 0.8648062348365784, 1.0446358919143677, 0.8956713676452637, 1.023498773574829, 0.9231890439987183, 1.1098686456680298, 1.034118890762329, 0.8658392429351807, 0.8897566199302673, 1.0427088737487793, 0.8191144466400146, 0.9048907160758972, 0.810591995716095, 0.8871107697486877, 0.8638091087341309, 0.8279356360435486, 0.8052234649658203, 0.8126195669174194, 0.9037814736366272, 0.8119953870773315, 0.8168088793754578, 0.9076420664787292, 0.8695063591003418, 0.8946489095687866, 0.8312411904335022, 0.8010362386703491, 0.8018356561660767, 0.7923034429550171, 0.8122982382774353, 1.0208925008773804, 0.7695151567459106, 0.8167126774787903, 0.8657716512680054, 0.8138982653617859, 0.8243890404701233, 0.8974142670631409, 0.9350436329841614, 0.8398781418800354, 0.8478838801383972, 0.8428386449813843, 0.8377269506454468, 0.8007234334945679, 0.8118352293968201, 0.8712694048881531, 0.9147471785545349, 0.8405612111091614, 0.808768630027771, 0.8517136573791504, 0.8725771307945251, 0.8204644322395325, 0.8538171052932739, 0.8785553574562073, 0.9078375697135925, 0.8163878917694092, 0.8608605265617371, 0.8321461081504822, 0.8524206280708313, 0.8732777237892151, 0.8079755306243896, 0.8345766663551331, 0.9579257965087891, 0.8530077338218689, 0.9068678617477417, 0.8957387804985046, 0.8258098363876343, 0.8201690316200256, 0.8636938333511353, 0.8183060884475708, 1.0324844121932983, 0.8847565650939941, 0.8423045873641968, 0.8884896636009216, 0.8290899395942688, 0.8050135970115662, 0.8652026653289795, 0.8180428743362427, 0.8250423669815063, 0.797443687915802, 0.9396191239356995, 0.8636574149131775, 0.8667284250259399, 0.8399718999862671, 0.8410444259643555, 0.835825502872467, 1.010884165763855, 0.816366970539093, 0.8249459862709045, 0.8456982374191284, 0.8223929405212402, 0.8319007754325867, 0.858227550983429, 0.8247122764587402, 0.8273741006851196, 0.8519291877746582, 0.8650890588760376, 0.8157523274421692, 0.888752818107605, 0.8375034928321838, 0.8570529222488403, 0.8475221395492554, 0.8263442516326904, 0.848304033279419, 0.8550413250923157, 0.8296778202056885, 0.8511236310005188, 0.8237369060516357, 0.8474432826042175, 0.8493977785110474, 0.8436986207962036, 0.8588868379592896, 0.8872855305671692, 0.8455564379692078, 0.9025909304618835, 0.8998332023620605, 0.8578558564186096, 0.9463175535202026, 0.8614919185638428, 0.8438622951507568, 0.9141963720321655, 0.8451058864593506, 0.8531581163406372, 0.8212366104125977, 0.8708930611610413, 0.8309637904167175, 0.8527339100837708, 0.8491531014442444, 0.8487040996551514, 0.8843746781349182, 0.820106565952301, 0.8187767863273621, 0.9117220640182495, 0.8303888440132141, 0.8741205930709839, 0.8526747226715088, 0.8744627833366394, 0.8281863331794739, 0.8993483185768127, 0.8594712615013123, 0.9445974826812744, 0.8296740055084229, 0.8507503867149353, 0.8290457725524902, 0.8374032378196716, 0.9618270397186279, 0.8462005853652954, 0.8157455921173096, 0.8705956339836121, 0.9022846817970276, 0.8315787315368652, 0.841839075088501, 0.8544735312461853, 0.8880444169044495, 0.8359872102737427, 0.8269618153572083, 0.8788483142852783, 0.8784828186035156, 0.8368018269538879, 0.8365805745124817, 0.898003339767456, 0.8440682888031006, 0.9034911394119263, 0.8952654004096985, 0.8470379114151001, 0.8638904094696045, 0.9240427613258362, 0.9330470561981201, 0.8750123977661133, 0.8900598883628845, 0.8809977769851685, 0.8433154225349426, 0.843971848487854, 0.9256012439727783, 0.8509350419044495, 0.8969373106956482, 0.8565472364425659, 0.8612687587738037, 0.8512605428695679, 0.8908506035804749, 0.8283276557922363, 0.8566940426826477, 0.8582881689071655, 0.8145039677619934, 0.8837809562683105, 0.9249382019042969, 0.8461785316467285], 'val_accuracy': [0.09749999642372131, 0.09669999778270721, 0.11829999834299088, 0.15049999952316284, 0.30489999055862427, 0.37229999899864197, 0.5393999814987183, 0.605400025844574, 0.6466000080108643, 0.6524999737739563, 0.5924000144004822, 0.697700023651123, 0.715399980545044, 0.7005000114440918, 0.7003999948501587, 0.7268000245094299, 0.6672999858856201, 0.7192999720573425, 0.6728000044822693, 0.7064999938011169, 0.6366000175476074, 0.6789000034332275, 0.7368000149726868, 0.7264000177383423, 0.6600000262260437, 0.7486000061035156, 0.717199981212616, 0.7476999759674072, 0.7304999828338623, 0.7366999983787537, 0.7484999895095825, 0.7560999989509583, 0.7512000203132629, 0.7279999852180481, 0.7566999793052673, 0.7526000142097473, 0.7211999893188477, 0.7368000149726868, 0.7278000116348267, 0.7576000094413757, 0.762499988079071, 0.7616999745368958, 0.7656999826431274, 0.7639999985694885, 0.7050999999046326, 0.7745000123977661, 0.7630000114440918, 0.745199978351593, 0.7656000256538391, 0.7580000162124634, 0.7423999905586243, 0.7218000292778015, 0.757099986076355, 0.7598999738693237, 0.7621999979019165, 0.7592999935150146, 0.7670999765396118, 0.7742000222206116, 0.7520999908447266, 0.7379000186920166, 0.7577000260353088, 0.769599974155426, 0.757099986076355, 0.7524999976158142, 0.7680000066757202, 0.7613999843597412, 0.7443000078201294, 0.7491999864578247, 0.7706000208854675, 0.7598999738693237, 0.7724999785423279, 0.7578999996185303, 0.755299985408783, 0.7754999995231628, 0.76910001039505, 0.7314000129699707, 0.7623000144958496, 0.7447999715805054, 0.754800021648407, 0.7699999809265137, 0.7727000117301941, 0.7651000022888184, 0.7764000296592712, 0.7164000272750854, 0.7533000111579895, 0.7720999717712402, 0.7587000131607056, 0.7742000222206116, 0.7782999873161316, 0.7687000036239624, 0.7791000008583069, 0.7773000001907349, 0.7831000089645386, 0.7391999959945679, 0.76910001039505, 0.7645999789237976, 0.7760000228881836, 0.772599995136261, 0.7759000062942505, 0.7418000102043152, 0.7817000150680542, 0.776199996471405, 0.7692000269889832, 0.7777000069618225, 0.7749999761581421, 0.7674999833106995, 0.7777000069618225, 0.7738999724388123, 0.7766000032424927, 0.7706000208854675, 0.7840999960899353, 0.7603999972343445, 0.7806000113487244, 0.7735999822616577, 0.7736999988555908, 0.7785999774932861, 0.7757999897003174, 0.774399995803833, 0.7817999720573425, 0.7723000049591064, 0.7828999757766724, 0.7770000100135803, 0.7817999720573425, 0.7713000178337097, 0.7760999798774719, 0.7666000127792358, 0.7781999707221985, 0.7590000033378601, 0.7567999958992004, 0.7792999744415283, 0.7516000270843506, 0.770799994468689, 0.7778000235557556, 0.7566999793052673, 0.7749000191688538, 0.7770000100135803, 0.7840999960899353, 0.7724000215530396, 0.7864999771118164, 0.7782999873161316, 0.7763000130653381, 0.7811999917030334, 0.7670999765396118, 0.7900999784469604, 0.785099983215332, 0.7613000273704529, 0.7832000255584717, 0.7749999761581421, 0.7745000123977661, 0.7674000263214111, 0.7806000113487244, 0.7588000297546387, 0.7770000100135803, 0.758400022983551, 0.7817999720573425, 0.7764999866485596, 0.7828999757766724, 0.781499981880188, 0.7522000074386597, 0.7793999910354614, 0.7870000004768372, 0.774399995803833, 0.7613999843597412, 0.7833999991416931, 0.784500002861023, 0.7767000198364258, 0.7634999752044678, 0.7872999906539917, 0.7904999852180481, 0.7739999890327454, 0.7699999809265137, 0.788100004196167, 0.784500002861023, 0.7662000060081482, 0.7811999917030334, 0.765500009059906, 0.772599995136261, 0.77920001745224, 0.7770000100135803, 0.761900007724762, 0.7563999891281128, 0.7745000123977661, 0.7670999765396118, 0.7739999890327454, 0.7804999947547913, 0.7870000004768372, 0.7652000188827515, 0.779699981212616, 0.7720000147819519, 0.776199996471405, 0.7789999842643738, 0.7824000120162964, 0.7735000252723694, 0.7925000190734863, 0.7817000150680542, 0.7815999984741211, 0.794700026512146, 0.7742000222206116, 0.7648000121116638, 0.7825000286102295]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "nN2z77iAkpft",
        "outputId": "65676aa1-958f-4576-d275-123b40a0d7cd"
      },
      "source": [
        "# Plot the training loss and validation loss\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training loss', 'validation loss'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0YlX04KibM8",
        "outputId": "2f7ad257-b910-49ee-9a79-d4a332191a97"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(x_train, y_train, verbose=2)\n",
        "print(test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1563/1563 - 7s - loss: 0.3549 - accuracy: 0.9506 - 7s/epoch - 4ms/step\n",
            "0.9505599737167358\n"
          ]
        }
      ]
    }
  ]
}